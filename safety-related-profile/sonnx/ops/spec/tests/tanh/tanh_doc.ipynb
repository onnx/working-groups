{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericjenn/working-groups/blob/ericjenn-srpwg-wg1/safety-related-profile/documents/profile_opset/div/div.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEKyVwTun7hf",
        "outputId": "56e0c81b-6aeb-4e95-f638-b7afb0dcd870"
      },
      "outputs": [],
      "source": [
        "\n",
        "#!pip install onnx onnxruntime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYvhVMxXoRwo",
        "outputId": "e9e35640-cabf-4728-f877-f152435eab0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X=[[1.00000000,2.00000000], [3.00000000,4.00000000]]\n",
            "Result: tanh(X)=[[0.76159418,0.96402758], [0.99505472,0.99932921]]\n",
            "X=[[1.00000000], [1.00000000]]\n",
            "Result: tanh(X)=[[0.76159418], [0.76159418]]\n",
            "X=[[0.00000000], [0.00000000]]\n",
            "Result: tanh(X)=[[0.00000000], [0.00000000]]\n",
            "X=[[-1.00000000], [-1.00000000]]\n",
            "Result: tanh(X)=[[-0.76159418], [-0.76159418]]\n",
            "X=[[inf], [inf]]\n",
            "Result: tanh(X)=[[1.00000000], [1.00000000]]\n",
            "X=[[-inf], [-inf]]\n",
            "Result: tanh(X)=[[-1.00000000], [-1.00000000]]\n",
            "X=[[nan], [nan]]\n",
            "Result: tanh(X)=[[nan], [nan]]\n",
            "\n",
            "## Example 1\n",
            "X=[[ 0.00000000, 1.00000000,-1.00000000]]\n",
            "Result: tanh(X)=[[ 0.00000000, 0.76159418,-0.76159418]]\n",
            "\n",
            "## Example 2\n",
            "X=[[-2.00000000, 0.00000000], [ 1.00000000, 2.00000000], [-4.00000000, 4.00000000]]\n",
            "Result: tanh(X)=[[-0.96402758, 0.00000000], [ 0.76159418, 0.96402758], [-0.99932921, 0.99932921]]\n",
            "\n",
            "## Example 3\n",
            "X=[[ inf, nan,-inf]]\n",
            "Result: tanh(X)=[[ 1.00000000,        nan,-1.00000000]]\n"
          ]
        }
      ],
      "source": [
        "import onnx\n",
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "\n",
        "# Define input and output tensor names\n",
        "input_name = \"X\"\n",
        "tanh_output_name = \"TanhOutput\"\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# 2-rank input tensor\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "# Create 2-rank input tensor\n",
        "input_tensor = onnx.helper.make_tensor_value_info(input_name,onnx.TensorProto.FLOAT,[None, None])\n",
        "\n",
        "# Create output tensor (final result after tanh operation)\n",
        "tanh_output = onnx.helper.make_tensor_value_info(tanh_output_name,onnx.TensorProto.FLOAT,[None, None])\n",
        "\n",
        "# Define Tanh node: Y = Tanh(X)\n",
        "tanh_node = onnx.helper.make_node(\"Tanh\",[input_name],[tanh_output_name])\n",
        "\n",
        "# Create the ONNX graph\n",
        "graph = onnx.helper.make_graph(\n",
        "    nodes=[tanh_node],\n",
        "    name=\"Tanh\",\n",
        "    inputs=[input_tensor],\n",
        "    outputs=[tanh_output]\n",
        ")\n",
        "\n",
        "# Create the ONNX model (Tanh available since early opsets, 13 is safe)\n",
        "model = onnx.helper.make_model(graph,opset_imports=[onnx.helper.make_opsetid(\"\", 13)])\n",
        "onnx.checker.check_model(model)\n",
        "\n",
        "# Save the model\n",
        "onnx.save(model, \"tanh.onnx\")\n",
        "\n",
        "# Load and run the model using ONNX Runtime\n",
        "session = ort.InferenceSession(\"tanh.onnx\")\n",
        "\n",
        "def do_tanh(x):\n",
        "    # Run inference\n",
        "    output = session.run(None, {input_name: x})\n",
        "\n",
        "    x_f = np.array2string(x, separator=',', max_line_width=np.inf).replace('\\n', '')\n",
        "    o_f = np.array2string(output[0], separator=',', max_line_width=np.inf).replace('\\n', '')\n",
        "\n",
        "    # Display results\n",
        "    print(f\"X={x_f}\")\n",
        "    print(f\"Result: tanh(X)={o_f}\")\n",
        "\n",
        "np.set_printoptions(precision=None, floatmode='fixed')\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------\n",
        "# Nominal cases\n",
        "#--------------------------------------------------------------------\n",
        "\n",
        "# Case N1: 2-rank tensor (float32)\n",
        "x = np.array([[1.0, 2.0],\n",
        "              [3.0, 4.0]], dtype=np.float32)\n",
        "\n",
        "do_tanh(x)\n",
        "\n",
        "#--------------------------------------------------------------------\n",
        "# Non nominal cases (nan, -inf, 0, negative values)\n",
        "#--------------------------------------------------------------------\n",
        "\n",
        "v = [1.0, 0.0, -1.0, float(\"inf\"), float(\"-inf\"), float(\"nan\")]\n",
        "\n",
        "for x_val in v:\n",
        "    x_np = np.array([[x_val],\n",
        "                     [x_val]], dtype=np.float32)\n",
        "    do_tanh(x_np)\n",
        "\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------\n",
        "# Examples from documentation\n",
        "#--------------------------------------------------------------------\n",
        "\n",
        "print(\"\\n## Example 1\")\n",
        "\n",
        "# Example 1\n",
        "# X = [0, 1, -1]\n",
        "x_example_1 = np.array([[0.0, 1.0, -1.0]], dtype=np.float32)\n",
        "do_tanh(x_example_1)\n",
        "\n",
        "print(\"\\n## Example 2\")\n",
        "\n",
        "# Example 2\n",
        "# X =\n",
        "# [[  -2   0 ]\n",
        "#  [  1    2  ]\n",
        "#  [ -4    4  ]]\n",
        "x_example_2 = np.array([\n",
        "    [-2.0,   0.0],\n",
        "    [1.0,    2.0],\n",
        "    [-4.0,   4.0]\n",
        "], dtype=np.float32)\n",
        "\n",
        "do_tanh(x_example_2)\n",
        "\n",
        "print(\"\\n## Example 3\")\n",
        "\n",
        "# Example 3\n",
        "# X =\n",
        "# [[  inf   nan   -inf]]\n",
        "x_example_3 = np.array([\n",
        "    [float(\"inf\"), float(\"nan\"), float(\"-inf\")]\n",
        "], dtype=np.float32)\n",
        "\n",
        "do_tanh(x_example_3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===================================================\n",
            "Input X (float64) = [ 0.00000000e+00  1.00000000e-08 -1.00000000e-08  1.00000000e+00\n",
            " -1.00000000e+00  5.00000000e+00 -5.00000000e+00  1.00000000e+01\n",
            " -1.00000000e+01  2.00000000e+01 -2.00000000e+01  5.00000000e+01\n",
            " -5.00000000e+01  8.00000000e+01 -8.00000000e+01  8.80000000e+01\n",
            " -8.80000000e+01  1.00000000e+02 -1.00000000e+02  1.00000000e+03\n",
            " -1.00000000e+03             inf            -inf             nan]\n",
            "===================================================\n",
            "\n",
            "ONNX Tanh (ORT float32)\n",
            "Y(float32) = [ 0.00000000e+00  9.99999905e-09 -9.99999905e-09  7.61594176e-01\n",
            " -7.61594176e-01  9.99909163e-01 -9.99909163e-01  1.00000000e+00\n",
            " -1.00000000e+00  1.00000000e+00 -1.00000000e+00  1.00000000e+00\n",
            " -1.00000000e+00  1.00000000e+00 -1.00000000e+00  1.00000000e+00\n",
            " -1.00000000e+00  1.00000000e+00 -1.00000000e+00  1.00000000e+00\n",
            " -1.00000000e+00  1.00000000e+00 -1.00000000e+00             nan]\n",
            "abs error vs fp64 = [0.00000000e+00 9.48953130e-16 9.48953130e-16 2.03366546e-08\n",
            " 2.03366546e-08 4.17412328e-08 4.17412328e-08 4.12230727e-09\n",
            " 4.12230727e-09 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00            nan]\n",
            "rel error vs fp64 = [0.00000000e+00 9.48953109e-08 9.48953109e-08 2.67027451e-08\n",
            " 2.67027451e-08 4.17450231e-08 4.17450231e-08 4.12230729e-09\n",
            " 4.12230729e-09 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00            nan]\n",
            "\n",
            "Technique 1 (branching: exp(2x) if x<0 else exp(-2x))\n",
            "Y(float32) = [ 0.00000000  0.00000000  0.00000000  0.76159412 -0.76159412  0.99990916\n",
            " -0.99990916  1.00000000 -1.00000000  1.00000000 -1.00000000  1.00000000\n",
            " -1.00000000  1.00000000 -1.00000000  1.00000000 -1.00000000  1.00000000\n",
            " -1.00000000  1.00000000 -1.00000000  1.00000000 -1.00000000         nan]\n",
            "abs error vs fp64 = [0.00000000e+00 1.00000000e-08 1.00000000e-08 3.92679902e-08\n",
            " 3.92679902e-08 4.17412328e-08 4.17412328e-08 4.12230727e-09\n",
            " 4.12230727e-09 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00            nan]\n",
            "rel error vs fp64 = [0.00000000e+00 9.99999978e-01 9.99999978e-01 5.15602567e-08\n",
            " 5.15602567e-08 4.17450231e-08 4.17450231e-08 4.12230729e-09\n",
            " 4.12230729e-09 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00            nan]\n",
            "\n",
            "Technique 2 (single formula exp(2x) / (exp(2x)+1))\n",
            "Y(float32) = [ 0.00000000  0.00000000  0.00000000  0.76159418 -0.76159412  0.99990922\n",
            " -0.99990916  1.00000000 -1.00000000  1.00000000 -1.00000000         nan\n",
            " -1.00000000         nan -1.00000000         nan -1.00000000         nan\n",
            " -1.00000000         nan -1.00000000         nan -1.00000000         nan]\n",
            "abs error vs fp64 = [0.00000000e+00 1.00000000e-08 1.00000000e-08 2.03366546e-08\n",
            " 3.92679902e-08 1.78634120e-08 4.17412328e-08 4.12230727e-09\n",
            " 4.12230727e-09 0.00000000e+00 0.00000000e+00            nan\n",
            " 0.00000000e+00            nan 0.00000000e+00            nan\n",
            " 0.00000000e+00            nan 0.00000000e+00            nan\n",
            " 0.00000000e+00            nan 0.00000000e+00            nan]\n",
            "rel error vs fp64 = [0.00000000e+00 9.99999978e-01 9.99999978e-01 2.67027451e-08\n",
            " 5.15602567e-08 1.78650340e-08 4.17450231e-08 4.12230729e-09\n",
            " 4.12230729e-09 0.00000000e+00 0.00000000e+00            nan\n",
            " 0.00000000e+00            nan 0.00000000e+00            nan\n",
            " 0.00000000e+00            nan 0.00000000e+00            nan\n",
            " 0.00000000e+00            nan 0.00000000e+00            nan]\n",
            "\n",
            "Technique 3 (single formula exp(-2x) / (1+exp(-2x)))\n",
            "Y(float32) = [ 0.00000000  0.00000000  0.00000000  0.76159412 -0.76159418  0.99990916\n",
            " -0.99990922  1.00000000 -1.00000000  1.00000000 -1.00000000  1.00000000\n",
            "         nan  1.00000000         nan  1.00000000         nan  1.00000000\n",
            "         nan  1.00000000         nan  1.00000000         nan         nan]\n",
            "abs error vs fp64 = [0.00000000e+00 1.00000000e-08 1.00000000e-08 3.92679902e-08\n",
            " 2.03366546e-08 4.17412328e-08 1.78634120e-08 4.12230727e-09\n",
            " 4.12230727e-09 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "            nan 0.00000000e+00            nan 0.00000000e+00\n",
            "            nan 0.00000000e+00            nan 0.00000000e+00\n",
            "            nan 0.00000000e+00            nan            nan]\n",
            "rel error vs fp64 = [0.00000000e+00 9.99999978e-01 9.99999978e-01 5.15602567e-08\n",
            " 2.67027451e-08 4.17450231e-08 1.78650340e-08 4.12230729e-09\n",
            " 4.12230729e-09 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "            nan 0.00000000e+00            nan 0.00000000e+00\n",
            "            nan 0.00000000e+00            nan 0.00000000e+00\n",
            "            nan 0.00000000e+00            nan            nan]\n",
            "\n",
            "Technique 4 (classic: (exp(x)-exp(-x))/(exp(x)+exp(-x)))\n",
            "Y(float32) = [ 0.00000000  0.00000000  0.00000000  0.76159418 -0.76159418  0.99990910\n",
            " -0.99990910  1.00000000 -1.00000000  1.00000000 -1.00000000  1.00000000\n",
            " -1.00000000  1.00000000 -1.00000000  1.00000000 -1.00000000         nan\n",
            "         nan         nan         nan         nan         nan         nan]\n",
            "abs error vs fp64 = [0.00000000e+00 1.00000000e-08 1.00000000e-08 2.03366546e-08\n",
            " 2.03366546e-08 1.01345878e-07 1.01345878e-07 4.12230727e-09\n",
            " 4.12230727e-09 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00            nan            nan            nan\n",
            "            nan            nan            nan            nan]\n",
            "rel error vs fp64 = [0.00000000e+00 9.99999978e-01 9.99999978e-01 2.67027451e-08\n",
            " 2.67027451e-08 1.01355080e-07 1.01355080e-07 4.12230729e-09\n",
            " 4.12230729e-09 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00            nan            nan            nan\n",
            "            nan            nan            nan            nan]\n",
            "\n",
            "Technique 5 (libm-like piecewise polynomial + exp clamp)\n",
            "Y(float32) = [ 0.00000000e+00  9.99999994e-09 -9.99999994e-09  7.61594117e-01\n",
            " -7.61594117e-01  9.99909222e-01 -9.99909222e-01  1.00000000e+00\n",
            " -1.00000000e+00  1.00000000e+00 -1.00000000e+00  1.00000000e+00\n",
            " -1.00000000e+00  1.00000000e+00 -1.00000000e+00  1.00000000e+00\n",
            " -1.00000000e+00  1.00000000e+00 -1.00000000e+00  1.00000000e+00\n",
            " -1.00000000e+00  1.00000000e+00 -1.00000000e+00             nan]\n",
            "abs error vs fp64 = [0.00000000e+00 6.07747099e-17 6.07747099e-17 3.92679902e-08\n",
            " 3.92679902e-08 1.78634120e-08 1.78634120e-08 4.12230727e-09\n",
            " 4.12230727e-09 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00            nan]\n",
            "rel error vs fp64 = [0.00000000e+00 6.07747086e-09 6.07747086e-09 5.15602567e-08\n",
            " 5.15602567e-08 1.78650340e-08 1.78650340e-08 4.12230729e-09\n",
            " 4.12230729e-09 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00            nan]\n",
            "\n",
            "Technique 6 (ONNX-like:Eigen/MLAS polynomial rational approximation)\n",
            "Y(float32) = [ 0.00000000e+00  9.99999994e-09 -9.99999994e-09  7.61594176e-01\n",
            " -7.61594176e-01  9.99909163e-01 -9.99909163e-01  1.00000000e+00\n",
            " -1.00000000e+00  1.00000000e+00 -1.00000000e+00  1.00000000e+00\n",
            " -1.00000000e+00  1.00000000e+00 -1.00000000e+00  1.00000000e+00\n",
            " -1.00000000e+00  1.00000000e+00 -1.00000000e+00  1.00000000e+00\n",
            " -1.00000000e+00  1.00000000e+00 -1.00000000e+00             nan]\n",
            "abs error vs fp64 = [0.00000000e+00 6.07747099e-17 6.07747099e-17 2.03366546e-08\n",
            " 2.03366546e-08 4.17412328e-08 4.17412328e-08 4.12230727e-09\n",
            " 4.12230727e-09 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00            nan]\n",
            "rel error vs fp64 = [0.00000000e+00 6.07747086e-09 6.07747086e-09 2.67027451e-08\n",
            " 2.67027451e-08 4.17450231e-08 4.17450231e-08 4.12230729e-09\n",
            " 4.12230729e-09 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00            nan]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_5140/348396083.py:21: RuntimeWarning: overflow encountered in exp\n",
            "  return ((np.exp(2.0 * x, dtype=np.float32) - 1.0) /\n",
            "/tmp/ipykernel_5140/348396083.py:22: RuntimeWarning: overflow encountered in exp\n",
            "  (np.exp(2.0 * x, dtype=np.float32) + 1.0)).astype(np.float32)\n",
            "/tmp/ipykernel_5140/348396083.py:21: RuntimeWarning: invalid value encountered in divide\n",
            "  return ((np.exp(2.0 * x, dtype=np.float32) - 1.0) /\n",
            "/tmp/ipykernel_5140/348396083.py:27: RuntimeWarning: overflow encountered in exp\n",
            "  return ((1.0 - np.exp(-2.0 * x, dtype=np.float32)) /\n",
            "/tmp/ipykernel_5140/348396083.py:28: RuntimeWarning: overflow encountered in exp\n",
            "  (1.0 + np.exp(-2.0 * x, dtype=np.float32))).astype(np.float32)\n",
            "/tmp/ipykernel_5140/348396083.py:27: RuntimeWarning: invalid value encountered in divide\n",
            "  return ((1.0 - np.exp(-2.0 * x, dtype=np.float32)) /\n",
            "/tmp/ipykernel_5140/348396083.py:33: RuntimeWarning: overflow encountered in exp\n",
            "  return ((np.exp(x, dtype=np.float32) - np.exp(-x, dtype=np.float32)) /\n",
            "/tmp/ipykernel_5140/348396083.py:34: RuntimeWarning: overflow encountered in exp\n",
            "  (np.exp(x, dtype=np.float32) + np.exp(-x, dtype=np.float32))).astype(np.float32)\n",
            "/tmp/ipykernel_5140/348396083.py:33: RuntimeWarning: invalid value encountered in divide\n",
            "  return ((np.exp(x, dtype=np.float32) - np.exp(-x, dtype=np.float32)) /\n"
          ]
        }
      ],
      "source": [
        "#--------------------------------------------------------------------\n",
        "# Precision comparison: float32 implementations vs float64 reference\n",
        "#--------------------------------------------------------------------\n",
        "\n",
        "def tanh_np_technique_1(x):\n",
        "    x = x.astype(np.float32)\n",
        "    y = np.empty_like(x, dtype=np.float32)\n",
        "\n",
        "    mask = x < 0\n",
        "    y[mask] = (np.exp(2.0 * x[mask], dtype=np.float32) - 1.0) / \\\n",
        "              (np.exp(2.0 * x[mask], dtype=np.float32) + 1.0)\n",
        "\n",
        "    y[~mask] = (1.0 - np.exp(-2.0 * x[~mask], dtype=np.float32)) / \\\n",
        "               (1.0 + np.exp(-2.0 * x[~mask], dtype=np.float32))\n",
        "\n",
        "    return y.astype(np.float32)\n",
        "\n",
        "\n",
        "def tanh_np_technique_2(x):\n",
        "    x = x.astype(np.float32)\n",
        "    return ((np.exp(2.0 * x, dtype=np.float32) - 1.0) /\n",
        "            (np.exp(2.0 * x, dtype=np.float32) + 1.0)).astype(np.float32)\n",
        "\n",
        "\n",
        "def tanh_np_technique_3(x):\n",
        "    x = x.astype(np.float32)\n",
        "    return ((1.0 - np.exp(-2.0 * x, dtype=np.float32)) /\n",
        "            (1.0 + np.exp(-2.0 * x, dtype=np.float32))).astype(np.float32)\n",
        "\n",
        "\n",
        "def tanh_np_technique_4(x):\n",
        "    x = x.astype(np.float32)\n",
        "    return ((np.exp(x, dtype=np.float32) - np.exp(-x, dtype=np.float32)) /\n",
        "            (np.exp(x, dtype=np.float32) + np.exp(-x, dtype=np.float32))).astype(np.float32)\n",
        "\n",
        "def tanh_np_technique_5(x):\n",
        "    x = x.astype(np.float32)\n",
        "    y = np.empty_like(x, dtype=np.float32)\n",
        "    ax = np.abs(x)\n",
        "\n",
        "    # Region 1: very small x\n",
        "    m1 = ax < 2**-12\n",
        "    y[m1] = x[m1]\n",
        "\n",
        "    # Region 2: |x| < 0.625  (minimax polynomial)\n",
        "    m2 = (ax >= 2**-12) & (ax < 0.625)\n",
        "    x2 = x[m2]\n",
        "    z = x2 * x2\n",
        "\n",
        "    # Coefficients inspired by libm (float32)\n",
        "    y[m2] = x2 + x2 * z * (\n",
        "        np.float32(-0.333333313) +\n",
        "        z * (np.float32(0.133333340) +\n",
        "        z * np.float32(-0.053968253))\n",
        "    )\n",
        "\n",
        "    # Region 3: 0.625 â‰¤ |x| < 9\n",
        "    m3 = (ax >= 0.625) & (ax < 9.0)\n",
        "    t = np.exp(np.float32(2.0) * ax[m3], dtype=np.float32)\n",
        "    y[m3] = np.sign(x[m3]) * (np.float32(1.0) - np.float32(2.0) / (t + np.float32(1.0)))\n",
        "\n",
        "    # Region 4: saturation\n",
        "    m4 = ax >= 9.0\n",
        "    y[m4] = np.sign(x[m4])\n",
        "\n",
        "    return y.astype(np.float32)\n",
        "\n",
        "def tanh_np_technique_6(x):\n",
        "    x = np.asarray(x, dtype=np.float32)\n",
        "\n",
        "    # Clamp thresholds used by Eigen/MLAS (non-FMA path)\n",
        "    clamp = np.float32(7.90531110763549805)\n",
        "\n",
        "    # tiny threshold where tanh(x) ~ x\n",
        "    tiny = np.float32(0.0004)\n",
        "\n",
        "    # clamp\n",
        "    x_c = np.minimum(np.maximum(x, -clamp), clamp)\n",
        "\n",
        "    # polynomial coefficients (Eigen/MLAS)\n",
        "    a1  = np.float32(4.89352455891786e-03)\n",
        "    a3  = np.float32(6.37261928875436e-04)\n",
        "    a5  = np.float32(1.48572235717979e-05)\n",
        "    a7  = np.float32(5.12229709037114e-08)\n",
        "    a9  = np.float32(-8.60467152213735e-11)\n",
        "    a11 = np.float32(2.00018790482477e-13)\n",
        "    a13 = np.float32(-2.76076847742355e-16)\n",
        "\n",
        "    b0 = np.float32(4.89352518554385e-03)\n",
        "    b2 = np.float32(2.26843463243900e-03)\n",
        "    b4 = np.float32(1.18534705686654e-04)\n",
        "    b6 = np.float32(1.19825839466702e-06)\n",
        "\n",
        "    x2 = x_c * x_c\n",
        "\n",
        "    # numerator polynomial p(x)\n",
        "    p = a13\n",
        "    p = p * x2 + a11\n",
        "    p = p * x2 + a9\n",
        "    p = p * x2 + a7\n",
        "    p = p * x2 + a5\n",
        "    p = p * x2 + a3\n",
        "    p = p * x2 + a1\n",
        "    p = p * x_c\n",
        "\n",
        "    # denominator polynomial q(x)\n",
        "    q = b6\n",
        "    q = q * x2 + b4\n",
        "    q = q * x2 + b2\n",
        "    q = q * x2 + b0\n",
        "\n",
        "    y = p / q\n",
        "\n",
        "    # tiny x => tanh(x) ~ x\n",
        "    y = np.where(np.abs(x) < tiny, x, y)\n",
        "\n",
        "    return y.astype(np.float32)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def compare_precision_vs_fp64(x_fp64):\n",
        "    print(\"\\n===================================================\")\n",
        "    print(f\"Input X (float64) = {x_fp64.flatten()}\")\n",
        "    print(\"===================================================\")\n",
        "\n",
        "    # Reference: float64 numpy tanh\n",
        "    y_ref = np.tanh(x_fp64)  # float64 reference\n",
        "\n",
        "    # Cast input to float32 for tested implementations\n",
        "    x_f32 = x_fp64.astype(np.float32)\n",
        "\n",
        "    results = {\n",
        "        \"ONNX Tanh (ORT float32)\": session.run(None, {input_name: x_f32})[0].astype(np.float32),\n",
        "        \"Technique 1 (branching: exp(2x) if x<0 else exp(-2x))\": tanh_np_technique_1(x_f32),\n",
        "        \"Technique 2 (single formula exp(2x) / (exp(2x)+1))\": tanh_np_technique_2(x_f32),\n",
        "        \"Technique 3 (single formula exp(-2x) / (1+exp(-2x)))\": tanh_np_technique_3(x_f32),\n",
        "        \"Technique 4 (classic: (exp(x)-exp(-x))/(exp(x)+exp(-x)))\": tanh_np_technique_4(x_f32),\n",
        "        \"Technique 5 (libm-like piecewise polynomial + exp clamp)\": tanh_np_technique_5(x_f32),\n",
        "        \"Technique 6 (ONNX-like:Eigen/MLAS polynomial rational approximation)\": tanh_np_technique_6(x_f32),\n",
        "    }\n",
        "\n",
        "    for name, y_f32 in results.items():\n",
        "        y_f64 = y_f32.astype(np.float64)\n",
        "\n",
        "        abs_err = np.abs(y_f64 - y_ref)\n",
        "        rel_err = abs_err / (np.abs(y_ref) + np.finfo(np.float64).eps)\n",
        "\n",
        "        print(f\"\\n{name}\")\n",
        "        print(f\"Y(float32) = {y_f32.flatten()}\")\n",
        "        print(f\"abs error vs fp64 = {abs_err.flatten()}\")\n",
        "        print(f\"rel error vs fp64 = {rel_err.flatten()}\")\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------\n",
        "# Stress test values (chosen to expose numerical limits)\n",
        "#--------------------------------------------------------------------\n",
        "\n",
        "test_values_fp64 = np.array([\n",
        "    0.0,\n",
        "    1e-8,\n",
        "    -1e-8,\n",
        "    1.0,\n",
        "    -1.0,\n",
        "    5.0,\n",
        "    -5.0,\n",
        "    10.0,\n",
        "    -10.0,\n",
        "    20.0,\n",
        "    -20.0,\n",
        "    50.0,\n",
        "    -50.0,\n",
        "    80.0,\n",
        "    -80.0,\n",
        "    88.0,      # near float32 exp overflow\n",
        "    -88.0,\n",
        "    100.0,\n",
        "    -100.0,\n",
        "    1e3,\n",
        "    -1e3,\n",
        "    np.inf,\n",
        "    -np.inf,\n",
        "    np.nan\n",
        "], dtype=np.float64)\n",
        "\n",
        "# 2-rank tensor as required by the ONNX model\n",
        "x_test_fp64 = test_values_fp64.reshape(-1, 1)\n",
        "\n",
        "compare_precision_vs_fp64(x_test_fp64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================== RANKING ====================\n",
            "Best -> Worst (based on max abs error)\n",
            "------------------------------------------------\n",
            "Rank | Technique | mean_abs | max_abs | rms\n",
            "   1 | Technique 5 (libm-like piecewise polynomial + exp clamp) | 5.326e-09 | 3.927e-08 | 1.278e-08\n",
            "   2 | Technique 6 (ONNX-like:Eigen/MLAS polynomial rational approximation) | 5.757e-09 | 4.174e-08 | 1.375e-08\n",
            "   3 | ONNX Tanh (ORT float32) | 5.757e-09 | 4.174e-08 | 1.375e-08\n",
            "   4 | Technique 1 (branching: exp(2x) if x<0 else exp(-2x)) | 8.272e-09 | 4.174e-08 | 1.720e-08\n",
            "   5 | Technique 2 (single formula exp(2x) / (exp(2x)+1)) | 8.674e-09 | 4.174e-08 | 1.581e-08\n",
            "   6 | Technique 3 (single formula exp(-2x) / (1+exp(-2x))) | 8.674e-09 | 4.174e-08 | 1.581e-08\n",
            "   7 | Technique 4 (classic: (exp(x)-exp(-x))/(exp(x)+exp(-x))) | 1.598e-08 | 1.013e-07 | 3.565e-08\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_5140/348396083.py:21: RuntimeWarning: overflow encountered in exp\n",
            "  return ((np.exp(2.0 * x, dtype=np.float32) - 1.0) /\n",
            "/tmp/ipykernel_5140/348396083.py:22: RuntimeWarning: overflow encountered in exp\n",
            "  (np.exp(2.0 * x, dtype=np.float32) + 1.0)).astype(np.float32)\n",
            "/tmp/ipykernel_5140/348396083.py:21: RuntimeWarning: invalid value encountered in divide\n",
            "  return ((np.exp(2.0 * x, dtype=np.float32) - 1.0) /\n",
            "/tmp/ipykernel_5140/348396083.py:27: RuntimeWarning: overflow encountered in exp\n",
            "  return ((1.0 - np.exp(-2.0 * x, dtype=np.float32)) /\n",
            "/tmp/ipykernel_5140/348396083.py:28: RuntimeWarning: overflow encountered in exp\n",
            "  (1.0 + np.exp(-2.0 * x, dtype=np.float32))).astype(np.float32)\n",
            "/tmp/ipykernel_5140/348396083.py:27: RuntimeWarning: invalid value encountered in divide\n",
            "  return ((1.0 - np.exp(-2.0 * x, dtype=np.float32)) /\n",
            "/tmp/ipykernel_5140/348396083.py:33: RuntimeWarning: overflow encountered in exp\n",
            "  return ((np.exp(x, dtype=np.float32) - np.exp(-x, dtype=np.float32)) /\n",
            "/tmp/ipykernel_5140/348396083.py:34: RuntimeWarning: overflow encountered in exp\n",
            "  (np.exp(x, dtype=np.float32) + np.exp(-x, dtype=np.float32))).astype(np.float32)\n",
            "/tmp/ipykernel_5140/348396083.py:33: RuntimeWarning: invalid value encountered in divide\n",
            "  return ((np.exp(x, dtype=np.float32) - np.exp(-x, dtype=np.float32)) /\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('Technique 5 (libm-like piecewise polynomial + exp clamp)',\n",
              "  np.float64(5.326409521631861e-09),\n",
              "  np.float64(3.926799019282612e-08),\n",
              "  np.float64(1.2779296974320608e-08)),\n",
              " ('Technique 6 (ONNX-like:Eigen/MLAS polynomial rational approximation)',\n",
              "  np.float64(5.756538671320927e-09),\n",
              "  np.float64(4.174123280353825e-08),\n",
              "  np.float64(1.3745840328355247e-08)),\n",
              " ('ONNX Tanh (ORT float32)',\n",
              "  np.float64(5.756538748553834e-09),\n",
              "  np.float64(4.174123280353825e-08),\n",
              "  np.float64(1.374584032835525e-08)),\n",
              " ('Technique 1 (branching: exp(2x) if x<0 else exp(-2x))',\n",
              "  np.float64(8.272306979971962e-09),\n",
              "  np.float64(4.174123280353825e-08),\n",
              "  np.float64(1.719782338856382e-08)),\n",
              " ('Technique 2 (single formula exp(2x) / (exp(2x)+1))',\n",
              "  np.float64(8.67375906455339e-09),\n",
              "  np.float64(4.174123280353825e-08),\n",
              "  np.float64(1.5813198900882747e-08)),\n",
              " ('Technique 3 (single formula exp(-2x) / (1+exp(-2x)))',\n",
              "  np.float64(8.67375906455339e-09),\n",
              "  np.float64(4.174123280353825e-08),\n",
              "  np.float64(1.5813198900882747e-08)),\n",
              " ('Technique 4 (classic: (exp(x)-exp(-x))/(exp(x)+exp(-x)))',\n",
              "  np.float64(1.5977039933506657e-08),\n",
              "  np.float64(1.0134587757892888e-07),\n",
              "  np.float64(3.564788557232498e-08))]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def rank_techniques(x_fp64, session, input_name):\n",
        "    # Reference\n",
        "    y_ref = np.tanh(x_fp64)\n",
        "\n",
        "    # input float32\n",
        "    x_f32 = x_fp64.astype(np.float32)\n",
        "\n",
        "    results = {\n",
        "        \"ONNX Tanh (ORT float32)\": session.run(None, {input_name: x_f32})[0].astype(np.float32),\n",
        "        \"Technique 1 (branching: exp(2x) if x<0 else exp(-2x))\": tanh_np_technique_1(x_f32),\n",
        "        \"Technique 2 (single formula exp(2x) / (exp(2x)+1))\": tanh_np_technique_2(x_f32),\n",
        "        \"Technique 3 (single formula exp(-2x) / (1+exp(-2x)))\": tanh_np_technique_3(x_f32),\n",
        "        \"Technique 4 (classic: (exp(x)-exp(-x))/(exp(x)+exp(-x)))\": tanh_np_technique_4(x_f32),\n",
        "        \"Technique 5 (libm-like piecewise polynomial + exp clamp)\": tanh_np_technique_5(x_f32),\n",
        "        \"Technique 6 (ONNX-like:Eigen/MLAS polynomial rational approximation)\": tanh_np_technique_6(x_f32),\n",
        "    }\n",
        "\n",
        "\n",
        "    ranking = []\n",
        "\n",
        "    for name, y_f32 in results.items():\n",
        "        y_f64 = y_f32.astype(np.float64)\n",
        "\n",
        "        abs_err = np.abs(y_f64 - y_ref)\n",
        "\n",
        "        # ignore NaNs for metrics\n",
        "        abs_err_clean = abs_err[np.isfinite(abs_err)]\n",
        "\n",
        "        mean_abs = np.mean(abs_err_clean)\n",
        "        max_abs = np.max(abs_err_clean)\n",
        "        rms_abs = np.sqrt(np.mean(abs_err_clean**2))\n",
        "\n",
        "        ranking.append((name, mean_abs, max_abs, rms_abs))\n",
        "\n",
        "    # Sort by max error first, then mean, then rms\n",
        "    ranking_sorted = sorted(ranking, key=lambda t: (t[2], t[1], t[3]))\n",
        "\n",
        "    # Display\n",
        "    print(\"\\n==================== RANKING ====================\")\n",
        "    print(\"Best -> Worst (based on max abs error)\")\n",
        "    print(\"------------------------------------------------\")\n",
        "    print(\"Rank | Technique | mean_abs | max_abs | rms\")\n",
        "    for i, (name, mean_abs, max_abs, rms_abs) in enumerate(ranking_sorted, start=1):\n",
        "        print(f\"{i:>4d} | {name:<20s} | {mean_abs:.3e} | {max_abs:.3e} | {rms_abs:.3e}\")\n",
        "\n",
        "    return ranking_sorted\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Stress test values\n",
        "# ------------------------------------------------------------\n",
        "test_values_fp64 = np.array([\n",
        "    0.0,\n",
        "    1e-8,\n",
        "    -1e-8,\n",
        "    1.0,\n",
        "    -1.0,\n",
        "    5.0,\n",
        "    -5.0,\n",
        "    10.0,\n",
        "    -10.0,\n",
        "    20.0,\n",
        "    -20.0,\n",
        "    50.0,\n",
        "    -50.0,\n",
        "    80.0,\n",
        "    -80.0,\n",
        "    88.0,\n",
        "    -88.0,\n",
        "    100.0,\n",
        "    -100.0,\n",
        "    1e3,\n",
        "    -1e3,\n",
        "    np.inf,\n",
        "    -np.inf,\n",
        "    np.nan\n",
        "], dtype=np.float64)\n",
        "\n",
        "x_test_fp64 = test_values_fp64.reshape(-1, 1)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Call ranking (replace session/input_name by ton ONNX session)\n",
        "# ------------------------------------------------------------\n",
        "rank_techniques(x_test_fp64, session, input_name)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyP+i8qgZsjFhcbLt3N58Sdn",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (.venv)",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
