{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "245013fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (1.19.0)\n",
      "Requirement already satisfied: onnxruntime in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (1.22.1)\n",
      "Requirement already satisfied: numpy>=1.22 in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from onnx) (2.2.6)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from onnx) (6.32.1)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from onnx) (4.15.0)\n",
      "Requirement already satisfied: ml_dtypes in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from onnx) (0.5.3)\n",
      "Requirement already satisfied: coloredlogs in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from onnxruntime) (25.2.10)\n",
      "Requirement already satisfied: packaging in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from onnxruntime) (25.0)\n",
      "Requirement already satisfied: sympy in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from onnxruntime) (1.14.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from sympy->onnxruntime) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fa9bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# Define input and output tensor names\n",
    "input_name = \"X\"\n",
    "shape_output_name = \"Y\"\n",
    "\n",
    "# Create the ONNX model with Shape operator\n",
    "def create_shape_model(input_rank, start, end, dtype):\n",
    "\n",
    "    #Create input tensor\n",
    "    input1 = onnx.helper.make_tensor_value_info(input_name, dtype, input_rank)\n",
    "\n",
    "    # Create output tensor (final result after shape operation)\n",
    "    shape_output = onnx.helper.make_tensor_value_info(shape_output_name, onnx.TensorProto.INT64, [None])\n",
    "\n",
    "    # Define shape node\n",
    "    shape_node = onnx.helper.make_node(\n",
    "        \"Shape\",\n",
    "        inputs=[input_name],\n",
    "        outputs=[shape_output_name],\n",
    "        start=start,\n",
    "        end=end\n",
    "    )\n",
    "\n",
    "    # Create the ONNX graph\n",
    "    graph_def = onnx.helper.make_graph(\n",
    "        [shape_node],\n",
    "        \"Shape\",\n",
    "        [input1],\n",
    "        [shape_output],\n",
    "    )\n",
    "\n",
    "    # Create the ONNX model\n",
    "    model = onnx.helper.make_model(graph_def, opset_imports=[onnx.helper.make_opsetid(\"\", 22)]) # Explicitly set opset to 22\n",
    "    model.ir_version = 10 \n",
    "    onnx.checker.check_model(model)\n",
    "\n",
    "    # Save the model\n",
    "    onnx.save(model, \"shape.onnx\")\n",
    "\n",
    "    # Load and run the model with ONNX Runtime\n",
    "    session = ort.InferenceSession(\"shape.onnx\")\n",
    "    return session\n",
    "\n",
    "def do_shapes(x, session):\n",
    "    # Run inference\n",
    "    output = session.run(None, {input_name: x})\n",
    "\n",
    "    x_f = (np.array2string(x, separator=',', max_line_width=np.inf).replace('\\n', ''))\n",
    "    y_f = (np.array2string(output[0], separator=',', max_line_width=np.inf).replace('\\n', ''))\n",
    "\n",
    "    # Display results\n",
    "    print(\"Shape of input tensor:\", x.shape)\n",
    "    print(f\"X={x_f}\")\n",
    "    print(\"Shape of output tensor:\", output[0].shape)\n",
    "    print(f\"Result = {y_f}\")\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=None, floatmode='fixed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9167448",
   "metadata": {},
   "source": [
    "## Nominal Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fda05307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input tensor: (2, 3, 4)\n",
      "X=[[[ 0, 1, 2, 3],  [ 4, 5, 6, 7],  [ 8, 9,10,11]], [[12,13,14,15],  [16,17,18,19],  [20,21,22,23]]]\n",
      "Shape of output tensor: (3,)\n",
      "Result = [2,3,4]\n"
     ]
    }
   ],
   "source": [
    "# Case N1: 3-rank tensor (int32), start = 0, end = 3\n",
    "onnx_type = onnx.TensorProto.INT32\n",
    "x = np.arange(24).reshape(2, 3, 4).astype(np.int32)\n",
    "input_shape = x.shape  \n",
    "start = 0\n",
    "end = 3\n",
    "session = create_shape_model([None,None,None], start, end, onnx_type)\n",
    "do_shapes(x, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07d55e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input tensor: (2, 3, 4)\n",
      "X=[[[ 0, 1, 2, 3],  [ 4, 5, 6, 7],  [ 8, 9,10,11]], [[12,13,14,15],  [16,17,18,19],  [20,21,22,23]]]\n",
      "Shape of output tensor: (1,)\n",
      "Result = [3]\n"
     ]
    }
   ],
   "source": [
    "# Case N2: 3-rank tensor (int32), start = 1, end = 2\n",
    "onnx_type = onnx.TensorProto.INT32\n",
    "x = np.arange(24).reshape(2, 3, 4).astype(np.int32)\n",
    "input_shape = x.shape  \n",
    "start = 1\n",
    "end = 2\n",
    "session = create_shape_model([None,None,None], start, end, onnx_type)\n",
    "do_shapes(x, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "648f16c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input tensor: (2, 3, 4)\n",
      "X=[[[ 0, 1, 2, 3],  [ 4, 5, 6, 7],  [ 8, 9,10,11]], [[12,13,14,15],  [16,17,18,19],  [20,21,22,23]]]\n",
      "Shape of output tensor: (0,)\n",
      "Result = []\n"
     ]
    }
   ],
   "source": [
    "# Case N3: 3-rank tensor (int32), start = 2, end = 2\n",
    "onnx_type = onnx.TensorProto.INT32\n",
    "x = np.arange(24).reshape(2, 3, 4).astype(np.int32)\n",
    "input_shape = x.shape  \n",
    "start = 2\n",
    "end = 2\n",
    "session = create_shape_model([None,None,None], start, end, onnx_type)\n",
    "do_shapes(x, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "713bfc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input tensor: (2, 3, 4)\n",
      "X=[[[ 0, 1, 2, 3],  [ 4, 5, 6, 7],  [ 8, 9,10,11]], [[12,13,14,15],  [16,17,18,19],  [20,21,22,23]]]\n",
      "Shape of output tensor: (2,)\n",
      "Result = [2,3]\n"
     ]
    }
   ],
   "source": [
    "# Case N4: 3-rank tensor (int32), start = -500, end = 2\n",
    "onnx_type = onnx.TensorProto.INT32\n",
    "x = np.arange(24).reshape(2, 3, 4).astype(np.int32)\n",
    "input_shape = x.shape  \n",
    "start = -500\n",
    "end = 2\n",
    "session = create_shape_model([None,None,None], start, end, onnx_type)\n",
    "do_shapes(x, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3910fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input tensor: (2, 3, 4)\n",
      "X=[[[ 0, 1, 2, 3],  [ 4, 5, 6, 7],  [ 8, 9,10,11]], [[12,13,14,15],  [16,17,18,19],  [20,21,22,23]]]\n",
      "Shape of output tensor: (3,)\n",
      "Result = [2,3,4]\n"
     ]
    }
   ],
   "source": [
    "# Case N5: 3-rank tensor (int32), start = 0, end = 1000\n",
    "onnx_type = onnx.TensorProto.INT32\n",
    "x = np.arange(24).reshape(2, 3, 4).astype(np.int32)\n",
    "input_shape = x.shape  \n",
    "start = 0\n",
    "end = 1000\n",
    "session = create_shape_model([None,None,None], start, end, onnx_type)\n",
    "do_shapes(x, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a42985b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input tensor: (2, 3, 4)\n",
      "X=[[[ 0, 1, 2, 3],  [ 4, 5, 6, 7],  [ 8, 9,10,11]], [[12,13,14,15],  [16,17,18,19],  [20,21,22,23]]]\n",
      "Shape of output tensor: (0,)\n",
      "Result = []\n"
     ]
    }
   ],
   "source": [
    "# Case N6: 3-rank tensor (int32), start = -500, end = -400\n",
    "onnx_type = onnx.TensorProto.INT32\n",
    "x = np.arange(24).reshape(2, 3, 4).astype(np.int32)\n",
    "input_shape = x.shape  \n",
    "start = -500\n",
    "end = -400\n",
    "session = create_shape_model([None,None,None], start, end, onnx_type)\n",
    "do_shapes(x, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17a051a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input tensor: (2, 3, 4)\n",
      "X=[[[ 0, 1, 2, 3],  [ 4, 5, 6, 7],  [ 8, 9,10,11]], [[12,13,14,15],  [16,17,18,19],  [20,21,22,23]]]\n",
      "Shape of output tensor: (0,)\n",
      "Result = []\n"
     ]
    }
   ],
   "source": [
    "# Case N7: 3-rank tensor (int32), start = 400, end = 500\n",
    "onnx_type = onnx.TensorProto.INT32\n",
    "x = np.arange(24).reshape(2, 3, 4).astype(np.int32)\n",
    "input_shape = x.shape  \n",
    "start = 400\n",
    "end = 500\n",
    "session = create_shape_model([None,None,None], start, end, onnx_type)\n",
    "do_shapes(x, session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypothesis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
