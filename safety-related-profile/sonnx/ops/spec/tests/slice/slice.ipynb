{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "245013fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in /home/jcm-machado/venv/lib/python3.13/site-packages (1.19.0)\n",
      "Requirement already satisfied: onnxruntime in /home/jcm-machado/venv/lib/python3.13/site-packages (1.22.1)\n",
      "Requirement already satisfied: numpy>=1.22 in /home/jcm-machado/venv/lib/python3.13/site-packages (from onnx) (2.2.6)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in /home/jcm-machado/venv/lib/python3.13/site-packages (from onnx) (6.32.1)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in /home/jcm-machado/venv/lib/python3.13/site-packages (from onnx) (4.15.0)\n",
      "Requirement already satisfied: ml_dtypes in /home/jcm-machado/venv/lib/python3.13/site-packages (from onnx) (0.5.3)\n",
      "Requirement already satisfied: coloredlogs in /home/jcm-machado/venv/lib/python3.13/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/jcm-machado/venv/lib/python3.13/site-packages (from onnxruntime) (25.2.10)\n",
      "Requirement already satisfied: packaging in /home/jcm-machado/venv/lib/python3.13/site-packages (from onnxruntime) (25.0)\n",
      "Requirement already satisfied: sympy in /home/jcm-machado/venv/lib/python3.13/site-packages (from onnxruntime) (1.14.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/jcm-machado/venv/lib/python3.13/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/jcm-machado/venv/lib/python3.13/site-packages (from sympy->onnxruntime) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31fa9bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    " \n",
    "# Define input and output tensor names\n",
    "x_tensor_name = \"X\"\n",
    "s_tensor_name = \"S\"\n",
    "e_tensor_name = \"E\"\n",
    "a_tensor_name = \"A\"\n",
    "k_tensor_name = \"K\"\n",
    "slice_output_name = \"Y\"\n",
    " \n",
    "# Create the ONNX model with Slice operator\n",
    "def create_slice_model(input_rank, dtype_x, dtype_s, output_shape):\n",
    " \n",
    "    #Create inputs tensors\n",
    "    x_onnx = onnx.helper.make_tensor_value_info(x_tensor_name, dtype_x, input_rank)\n",
    "    s_onnx = onnx.helper.make_tensor_value_info(s_tensor_name, dtype_s, [len(input_rank)])\n",
    "    e_onnx = onnx.helper.make_tensor_value_info(e_tensor_name, dtype_s, [len(input_rank)])\n",
    "    a_onnx = onnx.helper.make_tensor_value_info(a_tensor_name, dtype_s, [len(input_rank)])\n",
    "    k_onnx = onnx.helper.make_tensor_value_info(k_tensor_name, dtype_s, [len(input_rank)])\n",
    " \n",
    "    # Create output tensor (final result after slice operation)\n",
    "    slice_output = onnx.helper.make_tensor_value_info(slice_output_name, dtype_x, output_shape)\n",
    " \n",
    "    # Define slice node\n",
    "    slice_node = onnx.helper.make_node(\n",
    "        \"Slice\",\n",
    "        inputs=[x_tensor_name, s_tensor_name, e_tensor_name, a_tensor_name, k_tensor_name],\n",
    "        outputs=[slice_output_name]\n",
    "    )\n",
    " \n",
    "    # Create the ONNX graph\n",
    "    graph_def = onnx.helper.make_graph(\n",
    "        [slice_node],\n",
    "        \"Slice\",\n",
    "        [x_onnx, s_onnx, e_onnx, a_onnx, k_onnx],\n",
    "        [slice_output],\n",
    "    )\n",
    " \n",
    "    onnx_model = onnx.helper.make_model(graph_def)\n",
    " \n",
    "    #Let's freeze the opset.\n",
    "    del onnx_model.opset_import[:]\n",
    "    opset = onnx_model.opset_import.add()\n",
    "    opset.domain = ''\n",
    "    opset.version = 13\n",
    "    onnx_model.ir_version = 10\n",
    " \n",
    "    # Verify the model\n",
    "    onnx.checker.check_model(onnx_model)\n",
    " \n",
    "    # Save the model\n",
    "    onnx.save(onnx_model, \"slice.onnx\")\n",
    " \n",
    "    # Load and run the model with ONNX Runtime\n",
    "    session = ort.InferenceSession(\"slice.onnx\")\n",
    "    return session\n",
    " \n",
    "def do_slice(x, s, e, a, k, session):\n",
    "    # Run inference\n",
    "    output = session.run(None, {x_tensor_name: x, s_tensor_name: s, e_tensor_name: e, a_tensor_name: a, k_tensor_name: k})\n",
    "    x_f = (np.array2string(x, separator=',', max_line_width=np.inf).replace('\\n', ''))\n",
    "    y_f = (np.array2string(output[0], separator=',', max_line_width=np.inf).replace('\\n', ''))\n",
    " \n",
    "    # Display results\n",
    "    print(\"Shape of input tensor:\", x.shape)\n",
    "    print(f\"X={x_f}\")\n",
    "    print(\"Shape of output tensor:\", output[0].shape)\n",
    "    print(f\"Result = {y_f}\")\n",
    " \n",
    " \n",
    "np.set_printoptions(precision=None, floatmode='fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b3ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_shape(input_shape, starts, ends, axes, steps):\n",
    "    #Normalize axes\n",
    "    for i in range(len(axes)):\n",
    "        if axes[i] < 0:\n",
    "            axes[i] += len(input_shape)\n",
    "    #Normalize starts and ends\n",
    "    for i in range(len(starts)):\n",
    "        if starts[i] < 0:\n",
    "            starts[i] += input_shape[axes[i]]\n",
    "        if ends[i] < 0:\n",
    "            ends[i] += input_shape[axes[i]]\n",
    "\n",
    "    #Compute output shape\n",
    "    rank_input_tensor = len(input_shape)\n",
    "    output_shape = [0] * rank_input_tensor\n",
    "    # Y [C1] -> X [C1]\n",
    "    for i in range(rank_input_tensor):\n",
    "        space_i = ends[i] - starts[i]\n",
    "        k_val = steps[i]\n",
    "        f = 0 if space_i % k_val == 0 else 1\n",
    "        dY_i = (space_i // k_val) + f\n",
    "        #TODO Informal spec mal\n",
    "        output_shape[axes[i]] = int(dY_i)\n",
    "    print(\"Expected output shape:\", output_shape)\n",
    "    return output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9167448",
   "metadata": {},
   "source": [
    "## Nominal Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fda05307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output shape: [4, 3]\n",
      "Shape of input tensor: (5, 6)\n",
      "X=[[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9,10,11], [12,13,14,15,16,17], [18,19,20,21,22,23], [24,25,26,27,28,29]]\n",
      "Shape of output tensor: (4, 3)\n",
      "Result = [[ 1, 3, 5], [ 7, 9,11], [13,15,17], [19,21,23]]\n"
     ]
    }
   ],
   "source": [
    "# Case N1: 2-rank tensor (int32), start=[0,1], end=[4,6], axes=[0,1], steps=[1,2]\n",
    "input_type = onnx.TensorProto.INT32\n",
    "x = np.arange(30).reshape(5,6).astype(np.int32)\n",
    "s_type = onnx.TensorProto.INT32\n",
    "s_tensor = np.array([0,1]).astype(np.int32)\n",
    "e_tensor = np.array([4,6]).astype(np.int32)\n",
    "a_tensor = np.array([0,1]).astype(np.int32)\n",
    "k_tensor = np.array([1,2]).astype(np.int32)\n",
    "output_shape_ = output_shape(x.shape, s_tensor, e_tensor, a_tensor, k_tensor)\n",
    "session = create_slice_model(x.shape, input_type, s_type, output_shape_)\n",
    "do_slice(x, s_tensor, e_tensor, a_tensor, k_tensor, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21fb795e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape (5, 6)\n",
      "Expected output shape: [5, 6]\n",
      "Shape of input tensor: (5, 6)\n",
      "X=[[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9,10,11], [12,13,14,15,16,17], [18,19,20,21,22,23], [24,25,26,27,28,29]]\n",
      "Shape of output tensor: (5, 6)\n",
      "Result = [[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9,10,11], [12,13,14,15,16,17], [18,19,20,21,22,23], [24,25,26,27,28,29]]\n"
     ]
    }
   ],
   "source": [
    "# Case N2: 2-rank tensor (int32), axes=[0,1], start=[0,0], end=[5,6], steps=[1,1]\n",
    "# Complete tensor\n",
    "input_type = onnx.TensorProto.INT32\n",
    "x = np.arange(30).reshape(5,6).astype(np.int32)\n",
    "s_type = onnx.TensorProto.INT32\n",
    "s_tensor = np.array([0, 0]).astype(np.int32)\n",
    "e_tensor = np.array([5, 6]).astype(np.int32)\n",
    "a_tensor = np.array([0, 1]).astype(np.int32)\n",
    "k_tensor = np.array([1, 1]).astype(np.int32)\n",
    "print(\"input shape\", x.shape)\n",
    "output_shape_ = output_shape(x.shape, s_tensor, e_tensor, a_tensor, k_tensor)\n",
    "session = create_slice_model(x.shape, input_type, s_type, output_shape_)\n",
    "do_slice(x, s_tensor, e_tensor, a_tensor, k_tensor, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "566043ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape (5, 6)\n",
      "Expected output shape: [3, 2]\n",
      "Shape of input tensor: (5, 6)\n",
      "X=[[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9,10,11], [12,13,14,15,16,17], [18,19,20,21,22,23], [24,25,26,27,28,29]]\n",
      "Shape of output tensor: (3, 2)\n",
      "Result = [[ 5, 3], [11, 9], [17,15]]\n"
     ]
    }
   ],
   "source": [
    "# Case N3: 2-rank tensor (int32), axes=[0,1], start=[-5,-1], end=[3,2], steps=[1,-2]\n",
    "input_type = onnx.TensorProto.INT32\n",
    "x = np.arange(30).reshape(5,6).astype(np.int32)\n",
    "s_type = onnx.TensorProto.INT32\n",
    "s_tensor = np.array([-5, -1]).astype(np.int32)\n",
    "e_tensor = np.array([3, 2]).astype(np.int32)\n",
    "a_tensor = np.array([0, 1]).astype(np.int32)\n",
    "k_tensor = np.array([1, -2]).astype(np.int32)\n",
    "print(\"input shape\", x.shape)\n",
    "output_shape_ = output_shape(x.shape, s_tensor, e_tensor, a_tensor, k_tensor)\n",
    "session = create_slice_model(x.shape, input_type, s_type, output_shape_)\n",
    "do_slice(x, s_tensor, e_tensor, a_tensor, k_tensor, session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypothesis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
