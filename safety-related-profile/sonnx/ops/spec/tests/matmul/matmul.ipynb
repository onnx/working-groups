{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02a475ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (1.19.0)\n",
      "Requirement already satisfied: onnxruntime in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (1.22.1)\n",
      "Requirement already satisfied: numpy>=1.22 in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from onnx) (2.3.3)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from onnx) (6.32.1)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from onnx) (4.15.0)\n",
      "Requirement already satisfied: ml_dtypes in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from onnx) (0.5.3)\n",
      "Requirement already satisfied: coloredlogs in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from onnxruntime) (25.2.10)\n",
      "Requirement already satisfied: packaging in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from onnxruntime) (25.0)\n",
      "Requirement already satisfied: sympy in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from onnxruntime) (1.14.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from sympy->onnxruntime) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31fa9bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# Define input and output tensor names\n",
    "input1_name = \"A\"\n",
    "input2_name = \"B\"\n",
    "matmul_output_name = \"Y\"\n",
    "\n",
    "\n",
    "# Create the ONNX model with Matmul operator\n",
    "def create_matmul_model(dtype, output_rank):\n",
    "\n",
    "    #Create \"input-rank\" inputs tensors\n",
    "    input1 = onnx.helper.make_tensor_value_info(input1_name, dtype, [None,None])\n",
    "    input2 = onnx.helper.make_tensor_value_info(input2_name, dtype, [None,None])\n",
    "\n",
    "    # Create output tensor (final result after matmul operation)\n",
    "    matmul_output = onnx.helper.make_tensor_value_info(matmul_output_name, dtype, output_rank)\n",
    "\n",
    "    # Define matmul node\n",
    "    matmul_node = onnx.helper.make_node(\n",
    "        \"MatMul\",\n",
    "        inputs=[input1_name, input2_name],\n",
    "        outputs=[matmul_output_name],\n",
    "    )\n",
    "\n",
    "    # Create the ONNX graph\n",
    "    graph_def = onnx.helper.make_graph(\n",
    "        [matmul_node],\n",
    "        \"MatMul\",\n",
    "        [input1, input2],\n",
    "        [matmul_output],\n",
    "    )\n",
    "\n",
    "    # Create the ONNX model\n",
    "    model = onnx.helper.make_model(graph_def, opset_imports=[onnx.helper.make_opsetid(\"\", 13)]) # Explicitly set opset to 13\n",
    "    model.ir_version = 10 \n",
    "    onnx.checker.check_model(model)\n",
    "\n",
    "    # Save the model\n",
    "    onnx.save(model, \"matmul.onnx\")\n",
    "\n",
    "    # Load and run the model with ONNX Runtime\n",
    "    session = ort.InferenceSession(\"matmul.onnx\")\n",
    "    return session\n",
    "\n",
    "def do_matmul(a, b, session):\n",
    "    # Run inference\n",
    "    output = session.run(None, {input1_name: a, input2_name: b})\n",
    "\n",
    "    a_f = (np.array2string(a, separator=',', max_line_width=np.inf).replace('\\n', ''))\n",
    "    b_f = (np.array2string(b, separator=',', max_line_width=np.inf).replace('\\n', ''))\n",
    "    y_f = (np.array2string(output[0], separator=',', max_line_width=np.inf).replace('\\n', ''))\n",
    "\n",
    "    # Display results\n",
    "    print(f\"A={a_f}, B={b_f}\")\n",
    "    print(f\"Result = {y_f}\")\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=None, floatmode='fixed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9167448",
   "metadata": {},
   "source": [
    "## Nominal Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87196b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A=[[1,2], [3,4]], B=[[5,6], [7,8]]\n",
      "Result = [[19,22], [43,50]]\n"
     ]
    }
   ],
   "source": [
    "# Case N1: 2 simple matrices multiplication\n",
    "onnx_type = onnx.TensorProto.INT32\n",
    "a = np.array([[1, 2], [3, 4]], dtype=np.int32)\n",
    "b = np.array([[5, 6], [7, 8]], dtype=np.int32)\n",
    "session = create_matmul_model(onnx_type, [2,2])\n",
    "do_matmul(a, b, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f034cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A=[[0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0]], B=[[1,0,0,0,0], [0,1,0,0,0], [0,0,1,0,0], [0,0,0,1,0], [0,0,0,0,1]]\n",
      "Result = [[0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0]]\n"
     ]
    }
   ],
   "source": [
    "# Case N2: 2 simple matrices multiplication\n",
    "onnx_type = onnx.TensorProto.INT32\n",
    "a = np.array([[0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0]], dtype=np.int32)\n",
    "b = np.identity(5, dtype=np.int32)\n",
    "session = create_matmul_model(onnx_type, [5,5])\n",
    "do_matmul(a, b, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa8f0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A=[[1,2], [3,4], [5,6]], B=[[ 7, 8, 9], [10,11,12]]\n",
      "Result = [[ 27, 30, 33], [ 61, 68, 75], [ 95,106,117]]\n"
     ]
    }
   ],
   "source": [
    "# Case N3: 2 simple matrices multiplication\n",
    "onnx_type = onnx.TensorProto.INT32\n",
    "a = np.array([[1,2], [3,4], [5,6]], dtype=np.int32)\n",
    "b = np.array([[7,8,9], [10,11,12]], dtype=np.int32)\n",
    "session = create_matmul_model(onnx_type, [3,3])\n",
    "do_matmul(a, b, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e80cd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "(1, 3)\n",
      "A=[[1], [2], [3]], B=[[4,5,6]]\n",
      "Result = [[ 4, 5, 6], [ 8,10,12], [12,15,18]]\n"
     ]
    }
   ],
   "source": [
    "#Case N4: 2 simple matrices multiplication\n",
    "onnx_type = onnx.TensorProto.INT32\n",
    "a = np.array([[1], [2], [3]], dtype=np.int32)\n",
    "b = np.array([[4, 5, 6]], dtype=np.int32)\n",
    "session = create_matmul_model(onnx_type, [3,3])\n",
    "do_matmul(a, b, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef1ebed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A=[[4,5,6]], B=[[1], [2], [3]]\n",
      "Result = [[32]]\n"
     ]
    }
   ],
   "source": [
    "#Case N5: 2 simple matrices multiplication\n",
    "onnx_type = onnx.TensorProto.INT32\n",
    "a = np.array([[4, 5, 6]], dtype=np.int32)\n",
    "b = np.array([[1], [2], [3]], dtype=np.int32)\n",
    "session = create_matmul_model(onnx_type, [1,1])\n",
    "do_matmul(a, b, session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b109280f",
   "metadata": {},
   "source": [
    "## No nominal cases (nan and inf values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2c4787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A=[[ inf,-inf, nan], [ nan, inf,-inf]], B=[[1.00000000,2.00000000], [4.00000000,5.00000000], [7.00000000,8.00000000]]\n",
      "Result = [[nan,nan], [nan,nan]]\n"
     ]
    }
   ],
   "source": [
    "#Case N1: Infs and Nans\n",
    "onnx_type = onnx.TensorProto.FLOAT\n",
    "a = np.array([[np.inf, -np.inf, np.nan], [np.nan, np.inf, -np.inf]], dtype=np.float32)\n",
    "b = np.array([[1, 2], [4, 5], [7, 8]], dtype=np.float32)\n",
    "session = create_matmul_model(onnx_type, [2,2])\n",
    "do_matmul(a, b, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf7f34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A=[[inf,inf], [nan,inf]], B=[[1.00000000,2.00000000,3.00000000,4.00000000], [4.00000000,5.00000000,6.00000000,7.00000000]]\n",
      "Result = [[inf,inf,inf,inf], [nan,nan,nan,nan]]\n"
     ]
    }
   ],
   "source": [
    "#Case N2: Infs and Nans\n",
    "onnx_type = onnx.TensorProto.FLOAT\n",
    "a = np.array([[np.inf, np.inf], [np.nan, np.inf]], dtype=np.float32)\n",
    "b = np.array([[1, 2, 3, 4], [4, 5, 6, 7]], dtype=np.float32)\n",
    "session = create_matmul_model(onnx_type, [2,4])\n",
    "do_matmul(a, b, session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb656e35",
   "metadata": {},
   "source": [
    "## Empty tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14b7d0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A=[], B=[]\n",
      "Result = [[0]]\n"
     ]
    }
   ],
   "source": [
    "#Case N1: Empty tensors\n",
    "onnx_type = onnx.TensorProto.INT32\n",
    "a = np.array([], dtype=np.int32).reshape(1,0)\n",
    "b = np.array([], dtype=np.int32).reshape(0,1)\n",
    "session = create_matmul_model(onnx_type, [1,1])\n",
    "do_matmul(a, b, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5db09ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A=[], B=[]\n",
      "Result = []\n"
     ]
    }
   ],
   "source": [
    "#Case N2: Empty tensors\n",
    "onnx_type = onnx.TensorProto.INT32\n",
    "a = np.array([], dtype=np.int32).reshape(0,1)\n",
    "b = np.array([], dtype=np.int32).reshape(1,0)\n",
    "session = create_matmul_model(onnx_type, [0,0])\n",
    "do_matmul(a, b, session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypothesis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
