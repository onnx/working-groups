{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericjenn/working-groups/blob/ericjenn-srpwg-wg1/safety-related-profile/documents/profile_opset/div/div.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEKyVwTun7hf",
        "outputId": "56e0c81b-6aeb-4e95-f638-b7afb0dcd870"
      },
      "outputs": [],
      "source": [
        "\n",
        "#!pip install onnx onnxruntime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## Nominal Cases\n",
            "\n",
            "X (axis=1) = [[ 9.50000000,35.70000076]]\n",
            "Softmax(X) = [[4.18296517e-12,1.00000000e+00]]\n",
            "\n",
            "X (axis=0) = [[1.00000000,2.00000000,3.00000000], [4.00000000,5.00000000,6.00000000]]\n",
            "Softmax(X) = [[0.04742587,0.04742587,0.04742587], [0.95257413,0.95257413,0.95257413]]\n",
            "\n",
            "X (axis=1) = [[1.00000000,2.00000000,3.00000000], [4.00000000,5.00000000,6.00000000]]\n",
            "Softmax(X) = [[0.09003057,0.24472848,0.66524094], [0.09003057,0.24472848,0.66524094]]\n",
            "\n",
            "## Special Value Cases\n",
            "\n",
            "X (axis=0) = [[1.00000000,2.00000000,3.00000000], [4.00000000,5.00000000,       inf]]\n",
            "Softmax(X) = [[0.04742587,0.04742587,       nan], [0.95257413,0.95257413,       nan]]\n",
            "\n",
            "X (axis=1) = [[1.00000000,2.00000000,3.00000000], [4.00000000,5.00000000,       inf]]\n",
            "Softmax(X) = [[0.09003057,0.24472848,0.66524094], [       nan,       nan,       nan]]\n",
            "\n",
            "X (axis=0) = [[1.00000000,2.00000000,3.00000000], [4.00000000,5.00000000,      -inf]]\n",
            "Softmax(X) = [[0.04742587,0.04742587,1.00000000], [0.95257413,0.95257413,0.00000000]]\n",
            "\n",
            "X (axis=1) = [[1.00000000,2.00000000,3.00000000], [4.00000000,5.00000000,      -inf]]\n",
            "Softmax(X) = [[0.09003057,0.24472848,0.66524094], [0.26894143,0.73105860,0.00000000]]\n",
            "\n",
            "X (axis=0) = [[1.00000000,2.00000000,3.00000000], [4.00000000,5.00000000,       nan]]\n",
            "Softmax(X) = [[0.04742587,0.04742587,       nan], [0.95257413,0.95257413,       nan]]\n",
            "\n",
            "X (axis=1) = [[1.00000000,2.00000000,3.00000000], [4.00000000,5.00000000,       nan]]\n",
            "Softmax(X) = [[0.09003057,0.24472848,0.66524094], [       nan,       nan,       nan]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import onnx\n",
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "\n",
        "# Define input and output tensor names\n",
        "input_name = \"X\"\n",
        "softmax_output_name = \"SoftmaxOutput\"\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# 2-rank input tensor\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "# Create 2-rank input tensor\n",
        "input_tensor = onnx.helper.make_tensor_value_info(input_name, onnx.TensorProto.FLOAT, [None, None])\n",
        "\n",
        "# Create output tensor (final result after softmax operation)\n",
        "softmax_output = onnx.helper.make_tensor_value_info(softmax_output_name, onnx.TensorProto.FLOAT, [None, None])\n",
        "\n",
        "def create_softmax_model(axis=1):\n",
        "    # Define Softmax node: Y = Softmax(X) with axis\n",
        "    softmax_node = onnx.helper.make_node(\"Softmax\", [input_name], [softmax_output_name], axis=axis)\n",
        "    \n",
        "    # Create the ONNX graph\n",
        "    graph = onnx.helper.make_graph(\n",
        "        nodes=[softmax_node],\n",
        "        name=f\"Softmax_axis_{axis}\",\n",
        "        inputs=[input_tensor],\n",
        "        outputs=[softmax_output]\n",
        "    )\n",
        "\n",
        "    # Create the ONNX model (Softmax opset 13)\n",
        "    model = onnx.helper.make_model(graph, opset_imports=[onnx.helper.make_opsetid(\"\", 13)])\n",
        "    onnx.checker.check_model(model)\n",
        "    onnx.save(model, f\"softmax_axis_{axis}.onnx\")\n",
        "    return ort.InferenceSession(f\"softmax_axis_{axis}.onnx\")\n",
        "\n",
        "# Create sessions for axis=0 and axis=1\n",
        "session_axis0 = create_softmax_model(axis=0)\n",
        "session_axis1 = create_softmax_model(axis=1)\n",
        "\n",
        "def do_softmax(x, axis=1):\n",
        "    session = session_axis0 if axis==0 else session_axis1\n",
        "    output = session.run(None, {input_name: x})\n",
        "\n",
        "    x_f = np.array2string(x, separator=',', max_line_width=np.inf).replace('\\n', '')\n",
        "    o_f = np.array2string(output[0], separator=',', max_line_width=np.inf).replace('\\n', '')\n",
        "\n",
        "    print(f\"X (axis={axis}) = {x_f}\")\n",
        "    print(f\"Softmax(X) = {o_f}\\n\")\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=8, floatmode='fixed')\n",
        "\n",
        "#--------------------------------------------------------------------\n",
        "# Nominal cases\n",
        "#--------------------------------------------------------------------\n",
        "\n",
        "print(\"## Nominal Cases\\n\")\n",
        "\n",
        "# Case 1: 1x2 vector\n",
        "x = np.array([[9.5, 35.7]], dtype=np.float32)\n",
        "do_softmax(x, axis=1)\n",
        "\n",
        "# Case 2: 2x3 matrix\n",
        "x = np.array([[1.0, 2.0, 3.0],\n",
        "              [4.0, 5.0, 6.0]], dtype=np.float32)\n",
        "do_softmax(x, axis=0)\n",
        "do_softmax(x, axis=1)\n",
        "\n",
        "#--------------------------------------------------------------------\n",
        "# Special values: +inf, -inf, NaN\n",
        "#--------------------------------------------------------------------\n",
        "\n",
        "print(\"## Special Value Cases\\n\")\n",
        "\n",
        "# Case +inf\n",
        "x = np.array([[1, 2, 3],\n",
        "              [4, 5, np.inf]], dtype=np.float32)\n",
        "do_softmax(x, axis=0)\n",
        "do_softmax(x, axis=1)\n",
        "\n",
        "# Case -inf\n",
        "x = np.array([[1, 2, 3],\n",
        "              [4, 5, -np.inf]], dtype=np.float32)\n",
        "do_softmax(x, axis=0)\n",
        "do_softmax(x, axis=1)\n",
        "\n",
        "# Case NaN\n",
        "x = np.array([[1, 2, 3],\n",
        "              [4, 5, np.nan]], dtype=np.float32)\n",
        "do_softmax(x, axis=0)\n",
        "do_softmax(x, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "## Test 6: 3 flottants normaux + +inf\n",
            "X (axis=1) = [[1.00000000,2.00000000,3.00000000,       inf]]\n",
            "Softmax(X) = [[nan,nan,nan,nan]]\n",
            "\n",
            "\n",
            "## Test 7: 3 flottants normaux + -inf\n",
            "X (axis=1) = [[1.00000000,2.00000000,3.00000000,      -inf]]\n",
            "Softmax(X) = [[0.09003057,0.24472848,0.66524094,0.00000000]]\n",
            "\n",
            "\n",
            "## Test 8: 3 flottants normaux + NaN\n",
            "X (axis=1) = [[1.00000000,2.00000000,3.00000000,       nan]]\n",
            "Softmax(X) = [[nan,nan,nan,nan]]\n",
            "\n",
            "\n",
            "## Test 9: 3 flottants égaux à -0\n",
            "X (axis=1) = [[-0.00000000,-0.00000000,-0.00000000]]\n",
            "Softmax(X) = [[0.33333334,0.33333334,0.33333334]]\n",
            "\n",
            "\n",
            "## Test 10: 3 flottants -0, 0, 0\n",
            "X (axis=1) = [[-0.00000000, 0.00000000, 0.00000000]]\n",
            "Softmax(X) = [[0.33333334,0.33333334,0.33333334]]\n",
            "\n",
            "\n",
            "## Test 11: 3 flottants normaux + +inf et -inf\n",
            "X (axis=1) = [[1.00000000,2.00000000,3.00000000,       inf,      -inf]]\n",
            "Softmax(X) = [[nan,nan,nan,nan,nan]]\n",
            "\n",
            "\n",
            "## Test 12: 3 flottants normaux + +inf et NaN\n",
            "X (axis=1) = [[1.00000000,2.00000000,3.00000000,       inf,       nan]]\n",
            "Softmax(X) = [[nan,nan,nan,nan,nan]]\n",
            "\n",
            "\n",
            "## Test 13: 3 flottants normaux + +inf et +0\n",
            "X (axis=1) = [[1.00000000,2.00000000,3.00000000,       inf,0.00000000]]\n",
            "Softmax(X) = [[nan,nan,nan,nan,nan]]\n",
            "\n",
            "\n",
            "## Test 14: 3 flottants normaux + +inf et -0\n",
            "X (axis=1) = [[ 1.00000000, 2.00000000, 3.00000000,        inf,-0.00000000]]\n",
            "Softmax(X) = [[nan,nan,nan,nan,nan]]\n",
            "\n",
            "\n",
            "## Test 15: 3 flottants normaux + -inf et NaN\n",
            "X (axis=1) = [[1.00000000,2.00000000,3.00000000,      -inf,       nan]]\n",
            "Softmax(X) = [[nan,nan,nan,nan,nan]]\n",
            "\n",
            "\n",
            "## Test 16: 3 flottants normaux + -inf et +0\n",
            "X (axis=1) = [[1.00000000,2.00000000,3.00000000,      -inf,0.00000000]]\n",
            "Softmax(X) = [[0.08714432,0.23688284,0.64391428,0.00000000,0.03205860]]\n",
            "\n",
            "\n",
            "## Test 17: 3 flottants normaux + -inf et -0\n",
            "X (axis=1) = [[ 1.00000000, 2.00000000, 3.00000000,       -inf,-0.00000000]]\n",
            "Softmax(X) = [[0.08714432,0.23688284,0.64391428,0.00000000,0.03205860]]\n",
            "\n",
            "\n",
            "## Test 18: 3 flottants normaux <0 + -0 + +0\n",
            "X (axis=1) = [[-1.00000000,-2.00000000,-3.00000000,-0.00000000, 0.00000000]]\n",
            "Softmax(X) = [[0.14409682,0.05301026,0.01950138,0.39169577,0.39169577]]\n",
            "\n",
            "\n",
            "## Test 19: 3 flottants normaux >0 + -0 + +0\n",
            "X (axis=1) = [[ 1.00000000, 2.00000000, 3.00000000,-0.00000000, 0.00000000]]\n",
            "Softmax(X) = [[0.08443738,0.22952460,0.62391251,0.03106277,0.03106277]]\n",
            "\n",
            "\n",
            "## Test 20: 1 flottant >0, 1 flottant <0, -0, +0, 2\n",
            "X (axis=1) = [[ 1.00000000,-1.00000000,-0.00000000, 0.00000000, 2.00000000]]\n",
            "Softmax(X) = [[0.21789455,0.02948882,0.08015893,0.08015893,0.59229881]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#--------------------------------------------------------------------\n",
        "# Additional special cases (tests 6 to 20)\n",
        "#--------------------------------------------------------------------\n",
        "\n",
        "print(\"\\n## Test 6: 3 flottants normaux + +inf\")\n",
        "x_test_6 = np.array([[1.0, 2.0, 3.0, np.inf]], dtype=np.float32)\n",
        "do_softmax(x_test_6, axis=1)\n",
        "\n",
        "print(\"\\n## Test 7: 3 flottants normaux + -inf\")\n",
        "x_test_7 = np.array([[1.0, 2.0, 3.0, -np.inf]], dtype=np.float32)\n",
        "do_softmax(x_test_7, axis=1)\n",
        "\n",
        "print(\"\\n## Test 8: 3 flottants normaux + NaN\")\n",
        "x_test_8 = np.array([[1.0, 2.0, 3.0, np.nan]], dtype=np.float32)\n",
        "do_softmax(x_test_8, axis=1)\n",
        "\n",
        "print(\"\\n## Test 9: 3 flottants égaux à -0\")\n",
        "x_test_9 = np.array([[-0.0, -0.0, -0.0]], dtype=np.float32)\n",
        "do_softmax(x_test_9, axis=1)\n",
        "\n",
        "print(\"\\n## Test 10: 3 flottants -0, 0, 0\")\n",
        "x_test_10 = np.array([[-0.0, 0.0, 0.0]], dtype=np.float32)\n",
        "do_softmax(x_test_10, axis=1)\n",
        "\n",
        "print(\"\\n## Test 11: 3 flottants normaux + +inf et -inf\")\n",
        "x_test_11 = np.array([[1.0, 2.0, 3.0, np.inf, -np.inf]], dtype=np.float32)\n",
        "do_softmax(x_test_11, axis=1)\n",
        "\n",
        "print(\"\\n## Test 12: 3 flottants normaux + +inf et NaN\")\n",
        "x_test_12 = np.array([[1.0, 2.0, 3.0, np.inf, np.nan]], dtype=np.float32)\n",
        "do_softmax(x_test_12, axis=1)\n",
        "\n",
        "print(\"\\n## Test 13: 3 flottants normaux + +inf et +0\")\n",
        "x_test_13 = np.array([[1.0, 2.0, 3.0, np.inf, 0.0]], dtype=np.float32)\n",
        "do_softmax(x_test_13, axis=1)\n",
        "\n",
        "print(\"\\n## Test 14: 3 flottants normaux + +inf et -0\")\n",
        "x_test_14 = np.array([[1.0, 2.0, 3.0, np.inf, -0.0]], dtype=np.float32)\n",
        "do_softmax(x_test_14, axis=1)\n",
        "\n",
        "print(\"\\n## Test 15: 3 flottants normaux + -inf et NaN\")\n",
        "x_test_15 = np.array([[1.0, 2.0, 3.0, -np.inf, np.nan]], dtype=np.float32)\n",
        "do_softmax(x_test_15, axis=1)\n",
        "\n",
        "print(\"\\n## Test 16: 3 flottants normaux + -inf et +0\")\n",
        "x_test_16 = np.array([[1.0, 2.0, 3.0, -np.inf, 0.0]], dtype=np.float32)\n",
        "do_softmax(x_test_16, axis=1)\n",
        "\n",
        "print(\"\\n## Test 17: 3 flottants normaux + -inf et -0\")\n",
        "x_test_17 = np.array([[1.0, 2.0, 3.0, -np.inf, -0.0]], dtype=np.float32)\n",
        "do_softmax(x_test_17, axis=1)\n",
        "\n",
        "print(\"\\n## Test 18: 3 flottants normaux <0 + -0 + +0\")\n",
        "x_test_18 = np.array([[-1.0, -2.0, -3.0, -0.0, 0.0]], dtype=np.float32)\n",
        "do_softmax(x_test_18, axis=1)\n",
        "\n",
        "print(\"\\n## Test 19: 3 flottants normaux >0 + -0 + +0\")\n",
        "x_test_19 = np.array([[1.0, 2.0, 3.0, -0.0, 0.0]], dtype=np.float32)\n",
        "do_softmax(x_test_19, axis=1)\n",
        "\n",
        "print(\"\\n## Test 20: 1 flottant >0, 1 flottant <0, -0, +0, 2\")\n",
        "x_test_20 = np.array([[1.0, -1.0, -0.0, 0.0, 2.0]], dtype=np.float32)\n",
        "do_softmax(x_test_20, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Code for 3D dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X (axis=2) = [[[ 1.00000000, 2.00000000, 3.00000000],  [ 4.00000000, 5.00000000, 6.00000000]], [[10.00000000,20.00000000,30.00000000],  [40.00000000,50.00000000,60.00000000]]]\n",
            "Softmax(X) = [[[9.00305733e-02,2.44728476e-01,6.65240943e-01],  [9.00305733e-02,2.44728476e-01,6.65240943e-01]], [[2.06105999e-09,4.53978682e-05,9.99954581e-01],  [2.06105999e-09,4.53978682e-05,9.99954581e-01]]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import onnx\n",
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "\n",
        "# Define input and output tensor names\n",
        "input_name = \"X\"\n",
        "softmax_output_name = \"SoftmaxOutput\"\n",
        "\n",
        "def create_softmax_model(axis=1, rank=2):\n",
        "    \"\"\"\n",
        "    Crée un modèle ONNX Softmax pour un tenseur de rang `rank` et un axe `axis`.\n",
        "    \"\"\"\n",
        "    # Définition dynamique de la forme d'entrée et de sortie\n",
        "    shape = [None] * rank\n",
        "    input_tensor = onnx.helper.make_tensor_value_info(input_name, onnx.TensorProto.FLOAT, shape)\n",
        "    softmax_output = onnx.helper.make_tensor_value_info(softmax_output_name, onnx.TensorProto.FLOAT, shape)\n",
        "\n",
        "    # Crée le nœud Softmax\n",
        "    softmax_node = onnx.helper.make_node(\n",
        "        \"Softmax\",\n",
        "        inputs=[input_name],\n",
        "        outputs=[softmax_output_name],\n",
        "        axis=axis\n",
        "    )\n",
        "\n",
        "    # Crée le graphe ONNX\n",
        "    graph = onnx.helper.make_graph(\n",
        "        nodes=[softmax_node],\n",
        "        name=f\"Softmax_axis_{axis}_rank_{rank}\",\n",
        "        inputs=[input_tensor],\n",
        "        outputs=[softmax_output]\n",
        "    )\n",
        "\n",
        "    # Crée le modèle ONNX (opset 13)\n",
        "    model = onnx.helper.make_model(graph, opset_imports=[onnx.helper.make_opsetid(\"\", 13)])\n",
        "    onnx.checker.check_model(model)\n",
        "    onnx.save(model, f\"softmax_axis_{axis}_rank_{rank}.onnx\")\n",
        "    return ort.InferenceSession(f\"softmax_axis_{axis}_rank_{rank}.onnx\")\n",
        "\n",
        "def do_softmax(x, axis=1):\n",
        "    \"\"\"\n",
        "    Effectue le softmax sur le tenseur x le long de l'axe spécifié.\n",
        "    Crée une session ONNX adaptée au rang du tenseur et à l'axe.\n",
        "    \"\"\"\n",
        "    rank = x.ndim\n",
        "    session = create_softmax_model(axis=axis, rank=rank)\n",
        "    output = session.run(None, {input_name: x})\n",
        "\n",
        "    x_f = np.array2string(x, separator=',', max_line_width=np.inf).replace('\\n', '')\n",
        "    o_f = np.array2string(output[0], separator=',', max_line_width=np.inf).replace('\\n', '')\n",
        "\n",
        "    print(f\"X (axis={axis}) = {x_f}\")\n",
        "    print(f\"Softmax(X) = {o_f}\\n\")\n",
        "\n",
        "# Options d'affichage pour numpy\n",
        "np.set_printoptions(precision=8, floatmode='fixed')\n",
        "\n",
        "# Exemple avec un tenseur 3D\n",
        "x3d = np.array([\n",
        "    [[1, 2, 3], [4, 5, 6]],\n",
        "    [[10, 20, 30], [40, 50, 60]]\n",
        "], dtype=np.float32)\n",
        "\n",
        "do_softmax(x3d, axis=2)  # Softmax sur la dernière dimension"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyP+i8qgZsjFhcbLt3N58Sdn",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (.venv)",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
