
 (Availability : use the [When2Meet](https://www.when2meet.com/?34146939-oceVQ))
 
 #### 2025/02/13 

*To be completed.*

#### 2025/02/04 

*To be completed.*

#### 2025/01/15
##### Agenda
- Case of max:min/maxpool with NaN: for all operators, try to rely on the spec of Max and Min. (Nota: I don't like the spec NaN > Inf > ... I think that we should treat NaN as a special case because NaN is no normally  comparable and here we are defining a comparison...)
- Processing of existing issues: see [issues tagged "TLSE WG"](https://github.com/users/ericjenn/projects/4/views/14))
  - Clip
  - Relu
- Sujet pour CEtIC
- Interesting links identified by Jean-Loup in ONNX:
  - https://onnx.ai/onnx/repo-docs/DimensionDenotation.html
  - https://onnx.ai/onnx/repo-docs/TypeDenotation.html
  - https://onnx.ai/onnx/repo-docs/MetadataProps.html
- Status of formal specification of CONV (Mariem)
- Discussion about SONNX event in late Feb / March
##### Minutes
- review of Clip
- review of Relu
- creation of Relu
- discussion about CETiC
  
##### Actions
##### New actions
  - [ ] (1501-1, Jean-Baptiste) Faire une proposition de contenu pour une soumission Ã   CETiC
  - [ ] (1501-2, Jean-Loup) Remove the relation NaN>Inf... and replace it by an explicit test for NaNs... 
  - [ ] (1501-3, ???) Introduce the term "Scalar" and (our) concept of "type" (numerical / value type) in the glossary. 
  - [X] (1501-4, eric Clarify the meaning of "heterogeneous" in ONNX
    - ONNX, heterogeneous seems to mean that the inputs can be of different types. But this is not the case. For instance, operator `Where` has "heterogeneous" arguments but, in ORT, `Where` requires the same types for `X` and `Y`. For example, one cannot mix an int32 tensor with a float tensor, or an int32 tensor with an int64 tensor. There is no type promotion. 
    - Heterogeneous **seems** to mean that the operator have arguments of different type: boolean for B and other for `X` and `Y`. 
    - But this is not the case for operator `Add` that is also tagged `heterogeneous` even though all arguments must be of the same generic type `T`
(`Add(float,int)` is rejected and so is `(int32,int64)`). 
    - Tag "Heterogeneous" is automatically generated by ONNX' documentation generator that is located in [onnx/docs/gen_doc.py](https://github.com/onnx/onnx/blob/main/onnx/defs/gen_doc.py). It is set when the  `formal_parameter.is_homogeneous` boolean is FALSE. This boolean is set if the operator schemas defined in the `defs.cc` files (for instance, for `Where`: see [here](https://github.com/onnx/onnx/blob/main/onnx/defs/tensor/defs.cc#L2865). For the `Where` operator, the schema is the following:
    ```
    ONNX_OPERATOR_SET_SCHEMA(
    Where,
    16,
    OpSchema()
        .SetDoc(GET_OP_DOC_STR(std::string(Where_ver16_doc) + GenerateBroadcastingDocMul()))
        .Input(
            0,
            "condition",
            "When True (nonzero), yield X, otherwise yield Y",
            "B",
            OpSchema::Single,
            true, // <= This is the "homogeneous" boolean 
            1,
            OpSchema::NonDifferentiable)
        .Input(
            1,
            "X",
            "values selected at indices where condition is True",
            "T",
            OpSchema::Single,
            true,
            1,
            OpSchema::Differentiable)
        .Input(
            2,
            "Y",
            "values selected at indices where condition is False",
            "T",
            OpSchema::Single,
            true,
            1,
            OpSchema::Differentiable)
        .Output(
            0,
            "output",
            "Tensor of shape equal to the broadcasted shape of condition, X, and Y.",
            "T",
            OpSchema::Single,
            true,
            1,
            OpSchema::Differentiable)
        .TypeConstraint("B", {"tensor(bool)"}, "Constrain to boolean tensors.")
        .TypeConstraint(
            "T",
            OpSchema::all_tensor_types_ir4(),
            "Constrain input and output types to all tensor types (including bfloat).")
        .TypeAndShapeInferenceFunction([](InferenceContext& ctx) {
          propagateElemTypeFromInputToOutput(ctx, 1, 0);
          if (hasNInputShapes(ctx, 3)) {
            std::vector<const TensorShapeProto*> shapes;
            shapes.push_back(&ctx.getInputType(0)->tensor_type().shape());
            shapes.push_back(&ctx.getInputType(1)->tensor_type().shape());
            shapes.push_back(&ctx.getInputType(2)->tensor_type().shape());
            multidirectionalBroadcastShapeInference(
                shapes, *ctx.getOutputType(0)->mutable_tensor_type()->mutable_shape());
          }
        }));
    ``` 
    
      - As all boolean values are "true", "heterogeneous" should not be displayed... Maybe has the documentation generation pipeline changed...
      - Normally, "heterogeneous" refers to variadic arguments: it is set arguments do not need to be of the same type. 
      - The generation of "heterogeneous" appear in version ONNX 1.4.0. And it is always related to variadic arguments:
      ```python
      def generate_formal_parameter_tags(formal_parameter: OpSchema.FormalParameter) -> str:
    tags: list[str] = []
    if OpSchema.FormalParameterOption.Optional == formal_parameter.option:
        tags = ["optional"]
    elif OpSchema.FormalParameterOption.Variadic == formal_parameter.option:
        if formal_parameter.is_homogeneous:
            tags = ["variadic"]
        else:
            tags = ["variadic", "heterogeneous"]
    differentiable: OpSchema.DifferentiationCategory = (
        OpSchema.DifferentiationCategory.Differentiable
    )
    non_differentiable: OpSchema.DifferentiationCategory = (
        OpSchema.DifferentiationCategory.NonDifferentiable
    )
    if differentiable == formal_parameter.differentiation_category:
        tags.append("differentiable")
    elif non_differentiable == formal_parameter.differentiation_category:
        tags.append("non-differentiable")

    return "" if len(tags) == 0 else " (" + ", ".join(tags) + ")"
      ```


  - [ ] (1501-5, ???) Clarify how we handle  value constraints for attributes
  - [X] (1501-6,Eric) Check the actual behavior of Relu and LeakyRelu in ONNX. Check if alpha can be negative.
    - Relu: input [-1.0, 0.0, 1.0, float("nan")] =>  [ 0.  0.  1. nan]
    - Leaky relu: [-1.0, 0.0, 1.0, float("nan")] =>  [nan  0.  1. nan] with alpha = NaN, as expected. Alpha can be negative and the value for X<0 becomes positive.
  - [ ] (1501-7,???) Update the informal spec guidelines (enforce usage of ONNX names and provision of denotation, use of generic types: "with int in (int8,int16,...)" )

##### Past actions
None.