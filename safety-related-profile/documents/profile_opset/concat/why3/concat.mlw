module Concat

  use int.Int
  use map.Map
  use utils.Same
  use tensor.Shape
  use tensor.Tensor
  use sequence.Seq
  use list.ListRich as L
 

  (* =================== Concat shape ================================*)
  (** E4: defining s_k which is the sum of the different tensors dimension along the axis considered **)
  (*
	x_k: list (sequence) of input tensors
	axis: axis along which the concatenation is performed
  *)
  let rec function compute_s_k_at_axis (x_k: seq (tensor 'a)) (axis: int) : int =
    variant{x_k}  (* a_k has to decrease size *)
    match x_k with 
    | L.Nil -> 0
    | L.Cons hd tl -> (hd.shape.dims)[axis] + compute_s_k_at_axis tl axis 
    end
  
  (** E7: computing the shape (dimensions) of the output concatenated tensor **)
  (*
	  x_k: list (sequence) of input tensors
	  axis: axis along which the concatenation is performed
	  idx: The current index in an input tensor shape.dims sequence; idx must be 0 (zero) at the first call of  output_dims; 
	     it is incremented at each recursive call of output_dims
	  nb_dims: number of dimensions of an input tensor
  *)
  let rec function output_dims (x_k: seq (tensor 'a)) (axis: int) (idx: int) (nb_dims: int) : seq int =
  (* Stop case: Finished building *)
  variant { nb_dims - idx }
  if idx >= nb_dims then
    Seq.empty 
  else
    let value_for_idx =
      if idx = axis then
         compute_s_k_at_axis x_k axis (* Computes the s_k (sum of dimensions along the axis) for all k tensors*)
      else
         (x_k[0]).shape.dims[idx] (* Copies the value from x_k[0].shape.dims[i], without paying attention to the i' considered because according to (E6) all tensors have the same shape *)
    in
    (* Combine: output_dims[current_idx] followed by the rest*)
    (L.Cons value_for_idx (output_dims x_k axis (idx + 1) nb_dims) : seq int)
   

 (** E7: computing the shape (dimensions) of the output concatenated tensor **)
 (*
	  x_k: list (sequence) of input tensors
	  axis: axis along which the concatenation is performed
 *)
   let function output_shape (x_k: seq (tensor 'a)) (axis : int): shape =
                      (* The dimension of a_k[0] was selected because according to (E8) the input tensors have the same shape => same length *)
       ensures {length result.dims = Tensor.dim x_k[0]}
       { dims = (output_dims x_k axis 0 (Tensor.dim x_k[0]))} 
       
   
   (*======================= Concat value ================================*) 
   
   
  (** (E3): defining the local index i' for a i (global index) given **)
  (*
	  seq_D_axis: seq_D_axis is the sequence of all the d_k,axis for each k tensor
	  i_axis: value on the axis along which the concatenation is performed 
	  k: Current index in sequence seq_D_axis. Must be 0 at the first call of the function 
	  s_k: Current sum of the previous dimensions in seq_D_axis. Must be 0 at the first call of the function
  *)
  let rec rec_find_k_and_i_prime (seq_D_axis: seq int) (i_axis: int) (k: int) (s_k: int) : (int, int)
   variant { length seq_D_axis - k }  (* Termination measure *)
  =
    if i_axis < s_k + seq_D_axis[k] then (* Inequality (E5) to define to in which k tensor the local index i' is defined *)
      (k, (i_axis - s_k)) (* Definition (E5) by keeping the upper part of the inequality: i' = i - s_k *)
    else
      (* The global index i is superior to s_k + seq_D_axis[k] so the k tensor to define the local index i' is not the current one but next one k+1. Update the offset (s_k) by adding the length of the tensor we just checked (current tensor). *)
      rec_find_k_and_i_prime seq_D_axis i_axis (k + 1) (s_k + seq_D_axis[k])
      
  (** (E3) and (E2): defining the local index i' for a i (global index) given and computing the k associated to i'**)
  (*
    seq_D_axis: seq_D_axis is the sequence of all the D_k^axis for each k tensor
    i_axis: value on the axis along which the concatenation is performed
  *) 
  let find_k_and_i_prime (seq_D_axis: seq int) (i_axis: int) : (int, int) = rec_find_k_and_i_prime seq_D_axis i_axis 0 0
     
  (** Utils function to copy the actual index i and changing the value for the axis by i'*)
  (*
    s: seq `a is the sequence to copy
	  idx: value of the index equals to the axis  
	  value: value at replace at the idx position
  *)
  let rec list_update (s: seq 'a) (idx: int) (value: 'a) : seq 'a (** return my local index i' with the value along the axis changed**)
    requires { 0 <= idx < length s } 
    ensures { length result = length s }
    variant { idx } 
    = match s with 
        | L.Nil -> L.Nil 
        | L.Cons x xs -> if idx = 0 then 
                           L.Cons value xs : seq 'a 
                         else 
                           L.Cons x (list_update xs (idx - 1) value)
      end

  (** (E2): defining the mathematical formula that defines the concat operator**)
  (*
	  x_k: list (sequence) of input tensors
	  axis: axis along which the concatenation is performed
  *)
  let function output_value (x_k: seq (tensor 'a))(axis: int): (index -> 'a)
 (* ensures {pred_value_spec_concat x_k axis result} *)               
     
  =
    let seq_D_axis = map (fun t -> t.shape.dims[axis]) x_k in

    (* global indices i for my return value function *)
    fun (global_index: index) ->

      let i_axis = global_index[axis] in
      let (k, i_prime) = find_k_and_i_prime seq_D_axis i_axis in
      let local_index_k = list_update global_index axis i_prime in
      let source_tensor_k = x_k[k] in
      let result_value = source_tensor_k.value local_index_k in

      (*Return the computed value *)
      result_value

  (*goal g1: pred_value_spec *)
   
 (** (E1...E9): function that defines the formal definition of concat in informal specification **)
  (*
	  x_k: list (sequence) of input tensors
	  axis: axis along which the concatenation is performed
  *)
   let function concat (x_k: seq (tensor 'a)) (axis: int) : tensor 'a 
   requires{1 <= length x_k <= 2147483647}  (** (E1): bounded number of inputs **)
   requires { forall k: int. (0<= k < length x_k) -> 0 <= axis < Tensor.dim x_k[k] } (** (E9): bounded axis value **)
   requires { forall k: int. (0<= k < (Seq.length x_k)- 1) -> Tensor.dim x_k[k] = Tensor.dim x_k[k+1] } (** (E8): inputs having the same shape => same length **)
   requires { forall k i: int. 
                (0 <= k /\ k < (Seq.length x_k)- 1 )/\((0<= i < Tensor.dim x_k[k]) /\ (i <> axis)) -> x_k[k].shape.dims[i]=x_k[k+1].shape.dims[i] } (** (E6): inputs dimensions values match except along the axis **)
   
   = 
  {
    shape = (output_shape x_k axis);  (*(E7): definition of the output shape for the concatenated tensor *)
    value = (output_value x_k axis); (*(E2): mathematical defintion of the operator concat*)
  }


end
 
