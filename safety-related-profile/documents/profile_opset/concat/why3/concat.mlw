module Concat

  use int.Int
  use map.Map
  use utils.Same
  use tensor.Shape
  use tensor.Tensor
  use sequence.Seq
  use list.ListRich as L
  
  (* =================== Concat shape ================================*)
  (** E4: defining sigma_k which is the sum of the different tensors dimension along the axis considered **)
  let rec function compute_sigma_k_at_axis (a_k: seq (tensor 'a)) (axis: int) : int =
    variant{a_k}  (* a_k has to decrease size *)
    match a_k with 
    | L.Nil -> 0
    | L.Cons actual_tensor rest_of_the_list ->
      let dim_at_axis = (actual_tensor.shape.dims)[axis] in
        let sum_of_the_rest = compute_sigma_k_at_axis rest_of_the_list axis in 
          dim_at_axis + sum_of_the_rest
    end
   
  (** E7: computing the shape (dimensions) of the output concatenated tensor **)
  let rec function compute_output_dims (a_k: seq (tensor 'a)) (axis: int) (current_idx: int) (total_dims: int) : seq int =
  (* Stop case: Finished building *)
  variant { total_dims - current_idx }
  if current_idx >= total_dims then
    Seq.empty 
  else
    let value_for_this_index =
      if current_idx = axis then
         compute_sigma_k_at_axis a_k axis (* Computes the sigma_k (sum of dimensions along the axis) for all k tensors*)
      else
         let copy_tensor_dims = (a_k[0]).shape.dims in
         copy_tensor_dims[current_idx] (* Copies the value from a_k[0].shape.dims[i], without paying attention to the i' considered because according to (E6) all tensors have the same shape *)
    in
    let rest_of_the_sequence =
      compute_output_dims a_k axis (current_idx + 1) total_dims
    in
    (* Combine: output_dims[current_idx] followed by the rest*)
    (L.Cons value_for_this_index rest_of_the_sequence : seq int)
   

 (** E7: computing the shape (dimensions) of the output concatenated tensor **)
   let function compute_output_shape (a_k: seq (tensor 'a)) (axis : int): shape =
    let total_dim = Tensor.dim a_k[0] in  (* The dimension of a_k[0] was selected because according to (E8) the input tensors have the same shape => same length *)
      let output_seq_dim = compute_output_dims a_k axis 0 total_dim in 
       { dims = output_seq_dim } 
       
   
   (*======================= Concat value ================================*) 
   
   
  (** (E3): defining the local index i' for a i (global index) given **)
  let rec find_i_prime (seq_D_axis: seq int) (i_axis: int) (k: int) (sigma_k: int) : (int, int)
   variant { length seq_D_axis - k }  (* Termination measure; seq_D_axis is an array of all the D_k^axis for each k tensor *)
  =
    let len_k_d =  seq_D_axis[k] in (* This is D_k^axis *)

    if i_axis < sigma_k + len_k_d then (* Inequality (E5) to define to in which k tensor the local index i' is defined *)
      let i_prime = i_axis - sigma_k in (* Definition (E5) by keeping the upper part of the inequality: i' = i - sigma_k *)
      (k, i_prime)
    else
      (* The global index i is superior to sigma_k + len_k_d so the k tensor to define the local index i' is not the current one but next one k+1. Update the offset (sigma_k) by adding the length of the tensor we just checked (current tensor). *)
      find_i_prime seq_D_axis i_axis (k + 1) (sigma_k + len_k_d)
      
   (** (E3) and (E2): defining the local index i' for a i (global index) given and computing the k associated to i'**)
  let find_k_and_i_prime (seq_D_axis: seq int) (i_axis: int) : (int, int) =
     find_i_prime seq_D_axis i_axis 0 0
     
  (** Utils function to copy the actual index i and changing the value for the axis d by i'*)
  let rec list_update (s: seq 'a) (idx: int) (value: 'a) : seq 'a (** return my local index i' with the value along the axis changed**)
    requires { 0 <= idx < length s } variant { idx } ensures { length result = length s }
    = match s with | L.Nil -> L.Nil | L.Cons x xs -> if idx = 0 then L.Cons value xs : seq 'a else L.Cons x (list_update xs (idx - 1) value) end

  (** (E2): defining the mathematical formula that defines the concat operator**)
  let function compute_output_value (a_k: seq (tensor 'a))(axis: int): (index -> 'a)                
     
  =
    let seq_D_axis = map (fun t -> t.shape.dims[axis]) a_k in

    (* global indices i for my return value function *)
    fun (global_indices: index) ->

      let i_axis = global_indices[axis] in
      let (k, i_prime) = find_k_and_i_prime seq_D_axis i_axis in
      let local_indices_k = list_update global_indices axis i_prime in
      let source_tensor_k = a_k[k] in
      let result_value = source_tensor_k.value local_indices_k in

      (*Return the computed value *)
      result_value
   
   
 (** (E1...E9): function that defines the formal definition of concat in informal specification **)
   let function concat (a_k: seq (tensor 'a)) (axis: int) : tensor 'a 
   requires{1 <= length a_k <= 2147483647} (** (E1): bounded number of inputs **)
   requires { forall k: int. (0<= k < length a_k) -> 0 <= axis < Tensor.dim a_k[k] } (** (E9): bounded axis value **)
   requires { forall k: int. (0<= k < (Seq.length a_k)- 1) -> Tensor.dim a_k[k] = Tensor.dim a_k[k+1] } (** (E8): inputs having the same shape => same length **)
   requires { forall k i: int. 
                (0 <= k /\ k < (Seq.length a_k)- 1 )/\((0<= i < Tensor.dim a_k[k]) /\ (i <> axis)) -> a_k[k].shape.dims[i]=a_k[k+1].shape.dims[i] } (** (E6): inputs dimensions values match except along the axis **)
   ensures { forall i: int. 
                ((0<= i < Tensor.dim a_k[0]) /\ (i <> axis)) -> result.shape.dims[i]=a_k[0].shape.dims[i] } (** (E7): output concatanated tensor has the same shape as the inputs tensors except on the axis selected**)
   = 
  {
    shape = (compute_output_shape a_k axis);  (*(E7): definition of the output shape for the concatenated tensor *)
    value = (compute_output_value a_k axis); (*(E2): mathematical defintion of the operator concat*)
  }


end

  

  
