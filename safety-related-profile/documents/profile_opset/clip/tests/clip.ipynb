{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02a475ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (1.19.0)\n",
      "Requirement already satisfied: onnxruntime in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (1.22.1)\n",
      "Requirement already satisfied: numpy>=1.22 in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from onnx) (2.3.3)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from onnx) (6.32.1)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from onnx) (4.15.0)\n",
      "Requirement already satisfied: ml_dtypes in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from onnx) (0.5.3)\n",
      "Requirement already satisfied: coloredlogs in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from onnxruntime) (25.2.10)\n",
      "Requirement already satisfied: packaging in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from onnxruntime) (25.0)\n",
      "Requirement already satisfied: sympy in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from onnxruntime) (1.14.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/rm-silva/venvs/hypothesis-env/lib/python3.13/site-packages (from sympy->onnxruntime) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31fa9bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# Define input and output tensor names\n",
    "input1_name = \"X\"\n",
    "input2_name = \"L\"\n",
    "input3_name = \"M\"\n",
    "clip_output_name = \"Y\"\n",
    "\n",
    "\n",
    "# Create the ONNX model with Clip operator\n",
    "def create_clip_model(input_rank, dtype):\n",
    "\n",
    "    #Create \"input-rank\" input tensors and 2 scalars (min and max values for clipping)\n",
    "    input1 = onnx.helper.make_tensor_value_info(input1_name, dtype, input_rank)\n",
    "    input2 = onnx.helper.make_tensor_value_info(input2_name, dtype, [])\n",
    "    input3 = onnx.helper.make_tensor_value_info(input3_name, dtype, [])\n",
    "\n",
    "    # Create output tensor (final result after clip operation)\n",
    "    clip_output = onnx.helper.make_tensor_value_info(clip_output_name, dtype, input_rank)\n",
    "\n",
    "    # Define clip node\n",
    "    clip_node = onnx.helper.make_node(\n",
    "        \"Clip\",\n",
    "        inputs=[input1_name, input2_name, input3_name],\n",
    "        outputs=[clip_output_name],\n",
    "    )\n",
    "\n",
    "    # Create the ONNX graph\n",
    "    graph_def = onnx.helper.make_graph(\n",
    "        [clip_node],\n",
    "        \"Clip\",\n",
    "        [input1, input2, input3],\n",
    "        [clip_output],\n",
    "    )\n",
    "\n",
    "    # Create the ONNX model\n",
    "    model = onnx.helper.make_model(graph_def, opset_imports=[onnx.helper.make_opsetid(\"\", 13)]) # Explicitly set opset to 13\n",
    "    model.ir_version = 10 \n",
    "    onnx.checker.check_model(model)\n",
    "\n",
    "    # Save the model\n",
    "    onnx.save(model, \"clip.onnx\")\n",
    "\n",
    "    # Load and run the model with ONNX Runtime\n",
    "    session = ort.InferenceSession(\"clip.onnx\")\n",
    "    return session\n",
    "\n",
    "def do_clip(x, l, m, session):\n",
    "    # Run inference\n",
    "    output = session.run(None, {input1_name: x, input2_name: l, input3_name: m})\n",
    "\n",
    "    x_f = (np.array2string(x, separator=',', max_line_width=np.inf).replace('\\n', ''))\n",
    "    l_f = (np.array2string(l, separator=',', max_line_width=np.inf).replace('\\n', ''))\n",
    "    m_f = (np.array2string(m, separator=',', max_line_width=np.inf).replace('\\n', ''))\n",
    "    y_f = (np.array2string(output[0], separator=',', max_line_width=np.inf).replace('\\n', ''))\n",
    "\n",
    "    # Display results\n",
    "    print(f\"X={x_f}, L={l_f}, M={m_f}\")\n",
    "    print(f\"Result = {y_f}\")\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=None, floatmode='fixed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9167448",
   "metadata": {},
   "source": [
    "## Nominal Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87196b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[-2,-1, 0, 1, 2], L=-1, M=1\n",
      "Result = [-1,-1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Case N1: 1-rank tensor (int32), 2 scalars (int32)\n",
    "onnx_type = onnx.TensorProto.INT32\n",
    "x = np.array([-2, -1, 0, 1, 2], dtype=np.int32)\n",
    "l = np.array(-1, dtype=np.int32)\n",
    "m = np.array(1, dtype=np.int32)\n",
    "session = create_clip_model([None], onnx_type)\n",
    "do_clip(x, l, m, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "638b9c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[[-20,-10,  0, 10, 20], [-15,-10,  5, 10,  0]], L=-1, M=1\n",
      "Result = [[-1,-1, 0, 1, 1], [-1,-1, 1, 1, 0]]\n"
     ]
    }
   ],
   "source": [
    "# Case N2: 2-rank tensor (int32), 2 scalars (int32)\n",
    "onnx_type = onnx.TensorProto.INT32\n",
    "x = np.array([[-20,-10,0,10,20],[-15,-10,5,10,0]], dtype=np.int32)\n",
    "l = np.array(-1, dtype=np.int32)\n",
    "m = np.array(1, dtype=np.int32)\n",
    "session = create_clip_model([None, None], onnx_type)\n",
    "do_clip(x, l, m, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a4e6329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[-2.00000000,-1.00000000, 0.00000000, 1.00000000, 2.00000000], L=-1.00000000, M=1.00000000\n",
      "Result = [-1.00000000,-1.00000000, 0.00000000, 1.00000000, 1.00000000]\n"
     ]
    }
   ],
   "source": [
    "# Case N3: 1-rank tensor (float32), 2 scalars (float32)\n",
    "onnx_type = onnx.TensorProto.FLOAT\n",
    "x = np.array([-2.0, -1.0, 0.0, 1.0, 2.0], dtype=np.float32)\n",
    "l = np.array(-1.0, dtype=np.float32)\n",
    "m = np.array(1.0, dtype=np.float32)\n",
    "session = create_clip_model([None], onnx_type)\n",
    "do_clip(x, l, m, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78867c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[[-2.00000000,-1.00000000, 0.00000000, 1.00000000, 2.00000000], [-5.00000000,-2.50000000, 0.00000000, 2.50000000, 5.00000000]], L=-3.00000000, M=3.00000000\n",
      "Result = [[-2.00000000,-1.00000000, 0.00000000, 1.00000000, 2.00000000], [-3.00000000,-2.50000000, 0.00000000, 2.50000000, 3.00000000]]\n"
     ]
    }
   ],
   "source": [
    "# Case N4: 2-rank tensor (float32), 2 scalars (float32)\n",
    "onnx_type = onnx.TensorProto.FLOAT\n",
    "x = np.array([[-2.0, -1.0, 0.0, 1.0, 2.0],[-5.0, -2.5, 0.0, 2.5, 5.0]], dtype=np.float32)\n",
    "l = np.array(-3.0, dtype=np.float32)\n",
    "m = np.array(3.0, dtype=np.float32)\n",
    "session = create_clip_model([None,None], onnx_type)\n",
    "do_clip(x, l, m, session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "223f48c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[[-2.00000000,-1.00000000, 0.00000000, 1.00000000, 2.00000000], [-5.00000000,-2.50000000, 0.00000000, 2.50000000, 5.00000000]], L=10.00000000, M=5.00000000\n",
      "Result = [[5.00000000,5.00000000,5.00000000,5.00000000,5.00000000], [5.00000000,5.00000000,5.00000000,5.00000000,5.00000000]]\n"
     ]
    }
   ],
   "source": [
    "# Case N5: 2-rank tensor (float32), 2 scalars (float32), min > max\n",
    "onnx_type = onnx.TensorProto.FLOAT\n",
    "x = np.array([[-2.0, -1.0, 0.0, 1.0, 2.0],[-5.0, -2.5, 0.0, 2.5, 5.0]], dtype=np.float32)\n",
    "l = np.array(10.0, dtype=np.float32)\n",
    "m = np.array(5.0, dtype=np.float32)\n",
    "session = create_clip_model([None,None], onnx_type)\n",
    "do_clip(x, l, m, session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8a25b9",
   "metadata": {},
   "source": [
    "## No nominal cases (nan and inf values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a0e757d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[-2.00000000,-1.00000000, 0.00000000, 1.00000000,        nan], L=-1.00000000, M=1.00000000\n",
      "Result = [-1.00000000,-1.00000000, 0.00000000, 1.00000000,        nan]\n"
     ]
    }
   ],
   "source": [
    "# Case N1: 1-rank tensor (float32), 2 scalars (float32) -  Nan values in input tensor\n",
    "onnx_type = onnx.TensorProto.FLOAT\n",
    "x = np.array([-2.0, -1.0, 0.0, 1.0, np.nan], dtype=np.float32)\n",
    "l = np.array(-1.0, dtype=np.float32)\n",
    "m = np.array(1.0, dtype=np.float32)\n",
    "session = create_clip_model([None], onnx_type)\n",
    "do_clip(x, l, m, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e663f77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[-2.00000000,-1.00000000, 0.00000000, 1.00000000, 2.00000000], L=nan, M=1.00000000\n",
      "Result = [-2.00000000,-1.00000000, 0.00000000, 1.00000000, 1.00000000]\n"
     ]
    }
   ],
   "source": [
    "# Case N2: 1-rank tensor (float32), 2 scalars (float32) -  Nan values in L\n",
    "onnx_type = onnx.TensorProto.FLOAT\n",
    "x = np.array([-2.0, -1.0, 0.0, 1.0, 2.0], dtype=np.float32)\n",
    "l = np.array(np.nan, dtype=np.float32)\n",
    "m = np.array(1.0, dtype=np.float32)\n",
    "session = create_clip_model([None], onnx_type)\n",
    "do_clip(x, l, m, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ca723dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[-2.00000000,-1.00000000, 0.00000000, 1.00000000, 2.00000000], L=-1.00000000, M=nan\n",
      "Result = [-1.00000000,-1.00000000, 0.00000000, 1.00000000, 2.00000000]\n"
     ]
    }
   ],
   "source": [
    "# Case N3: 1-rank tensor (float32), 2 scalars (float32) -  Nan values in M\n",
    "onnx_type = onnx.TensorProto.FLOAT\n",
    "x = np.array([-2.0, -1.0, 0.0, 1.0, 2.0], dtype=np.float32)\n",
    "l = np.array(-1, dtype=np.float32)\n",
    "m = np.array(np.nan, dtype=np.float32)\n",
    "session = create_clip_model([None], onnx_type)\n",
    "do_clip(x, l, m, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8bb2b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[-2.00000000,-1.00000000, 0.00000000, 1.00000000, 2.00000000], L=nan, M=nan\n",
      "Result = [-2.00000000,-1.00000000, 0.00000000, 1.00000000, 2.00000000]\n"
     ]
    }
   ],
   "source": [
    "# Case N4: 1-rank tensor (float32), 2 scalars (float32) -  Nan values in L and M\n",
    "onnx_type = onnx.TensorProto.FLOAT\n",
    "x = np.array([-2.0, -1.0, 0.0, 1.0, 2.0], dtype=np.float32)\n",
    "l = np.array(np.nan, dtype=np.float32)\n",
    "m = np.array(np.nan, dtype=np.float32)\n",
    "session = create_clip_model([None], onnx_type)\n",
    "do_clip(x, l, m, session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypothesis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
